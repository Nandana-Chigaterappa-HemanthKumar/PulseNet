{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":81933,"databundleVersionId":9643020,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport warnings\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings('ignore', category=FutureWarning)\npath = '../input/child-mind-institute-problematic-internet-use/'\n\n# Load the training data\ntrain = pd.read_csv(path+'train.csv')\ntrain.head(5)\n\n#don's consider physical data like Physical Measures, FitnessGram Vitals and Treadmill, FitnessGram Child, Bio-electric Impedance Analysis, ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:40:27.652334Z","iopub.execute_input":"2024-11-22T09:40:27.652736Z","iopub.status.idle":"2024-11-22T09:40:29.046247Z","shell.execute_reply.started":"2024-11-22T09:40:27.652704Z","shell.execute_reply":"2024-11-22T09:40:29.044870Z"}},"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"         id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n0  00008ff9                      Fall                5                0   \n1  000fd460                    Summer                9                0   \n2  00105258                    Summer               10                1   \n3  00115b9f                    Winter                9                0   \n4  0016bb22                    Spring               18                1   \n\n  CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n0      Winter             51.0            Fall     16.877316             46.0   \n1         NaN              NaN            Fall     14.035590             48.0   \n2        Fall             71.0            Fall     16.648696             56.5   \n3        Fall             71.0          Summer     18.292347             56.0   \n4      Summer              NaN             NaN           NaN              NaN   \n\n   Physical-Weight  ...  PCIAT-PCIAT_18  PCIAT-PCIAT_19  PCIAT-PCIAT_20  \\\n0             50.8  ...             4.0             2.0             4.0   \n1             46.0  ...             0.0             0.0             0.0   \n2             75.6  ...             2.0             1.0             1.0   \n3             81.6  ...             3.0             4.0             1.0   \n4              NaN  ...             NaN             NaN             NaN   \n\n   PCIAT-PCIAT_Total SDS-Season  SDS-SDS_Total_Raw  SDS-SDS_Total_T  \\\n0               55.0        NaN                NaN              NaN   \n1                0.0       Fall               46.0             64.0   \n2               28.0       Fall               38.0             54.0   \n3               44.0     Summer               31.0             45.0   \n4                NaN        NaN                NaN              NaN   \n\n   PreInt_EduHx-Season PreInt_EduHx-computerinternet_hoursday  sii  \n0                 Fall                                    3.0  2.0  \n1               Summer                                    0.0  0.0  \n2               Summer                                    2.0  0.0  \n3               Winter                                    0.0  1.0  \n4                  NaN                                    NaN  NaN  \n\n[5 rows x 82 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Enroll_Season</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-Season</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Season</th>\n      <th>Physical-BMI</th>\n      <th>Physical-Height</th>\n      <th>Physical-Weight</th>\n      <th>...</th>\n      <th>PCIAT-PCIAT_18</th>\n      <th>PCIAT-PCIAT_19</th>\n      <th>PCIAT-PCIAT_20</th>\n      <th>PCIAT-PCIAT_Total</th>\n      <th>SDS-Season</th>\n      <th>SDS-SDS_Total_Raw</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-Season</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n      <th>sii</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>Fall</td>\n      <td>5</td>\n      <td>0</td>\n      <td>Winter</td>\n      <td>51.0</td>\n      <td>Fall</td>\n      <td>16.877316</td>\n      <td>46.0</td>\n      <td>50.8</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>55.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>Summer</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>14.035590</td>\n      <td>48.0</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Fall</td>\n      <td>46.0</td>\n      <td>64.0</td>\n      <td>Summer</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>Summer</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Fall</td>\n      <td>16.648696</td>\n      <td>56.5</td>\n      <td>75.6</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>28.0</td>\n      <td>Fall</td>\n      <td>38.0</td>\n      <td>54.0</td>\n      <td>Summer</td>\n      <td>2.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>Winter</td>\n      <td>9</td>\n      <td>0</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Summer</td>\n      <td>18.292347</td>\n      <td>56.0</td>\n      <td>81.6</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>1.0</td>\n      <td>44.0</td>\n      <td>Summer</td>\n      <td>31.0</td>\n      <td>45.0</td>\n      <td>Winter</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>Spring</td>\n      <td>18</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 82 columns</p>\n</div>"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"print(f\"Train shape: {train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.185772Z","iopub.execute_input":"2024-11-18T18:48:26.186110Z","iopub.status.idle":"2024-11-18T18:48:26.191759Z","shell.execute_reply.started":"2024-11-18T18:48:26.186076Z","shell.execute_reply":"2024-11-18T18:48:26.190632Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the data dictionary data\ndata_dictionary = pd.read_csv(path+'data_dictionary.csv')\ndata_dictionary.head(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T04:16:59.636886Z","iopub.execute_input":"2024-11-20T04:16:59.637262Z","iopub.status.idle":"2024-11-20T04:16:59.655568Z","shell.execute_reply.started":"2024-11-20T04:16:59.637229Z","shell.execute_reply":"2024-11-20T04:16:59.654544Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                           Instrument                      Field  \\\n0                          Identifier                         id   \n1                        Demographics  Basic_Demos-Enroll_Season   \n2                        Demographics            Basic_Demos-Age   \n3                        Demographics            Basic_Demos-Sex   \n4  Children's Global Assessment Scale                CGAS-Season   \n\n               Description             Type                        Values  \\\n0         Participant's ID              str                           NaN   \n1     Season of enrollment              str  Spring, Summer, Fall, Winter   \n2       Age of participant            float                           NaN   \n3       Sex of participant  categorical int                           0,1   \n4  Season of participation              str  Spring, Summer, Fall, Winter   \n\n       Value Labels  \n0               NaN  \n1               NaN  \n2               NaN  \n3  0=Male, 1=Female  \n4               NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Instrument</th>\n      <th>Field</th>\n      <th>Description</th>\n      <th>Type</th>\n      <th>Values</th>\n      <th>Value Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Identifier</td>\n      <td>id</td>\n      <td>Participant's ID</td>\n      <td>str</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Demographics</td>\n      <td>Basic_Demos-Enroll_Season</td>\n      <td>Season of enrollment</td>\n      <td>str</td>\n      <td>Spring, Summer, Fall, Winter</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Demographics</td>\n      <td>Basic_Demos-Age</td>\n      <td>Age of participant</td>\n      <td>float</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Demographics</td>\n      <td>Basic_Demos-Sex</td>\n      <td>Sex of participant</td>\n      <td>categorical int</td>\n      <td>0,1</td>\n      <td>0=Male, 1=Female</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Children's Global Assessment Scale</td>\n      <td>CGAS-Season</td>\n      <td>Season of participation</td>\n      <td>str</td>\n      <td>Spring, Summer, Fall, Winter</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"# Load the test data\ntest = pd.read_csv(path+'test.csv')\ntest.head(21)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:40:33.003219Z","iopub.execute_input":"2024-11-22T09:40:33.003707Z","iopub.status.idle":"2024-11-22T09:40:33.044266Z","shell.execute_reply.started":"2024-11-22T09:40:33.003668Z","shell.execute_reply":"2024-11-22T09:40:33.043200Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"          id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n0   00008ff9                      Fall                5                0   \n1   000fd460                    Summer                9                0   \n2   00105258                    Summer               10                1   \n3   00115b9f                    Winter                9                0   \n4   0016bb22                    Spring               18                1   \n5   001f3379                    Spring               13                1   \n6   0038ba98                      Fall               10                0   \n7   0068a485                      Fall               10                1   \n8   0069fbed                    Summer               15                0   \n9   0083e397                    Summer               19                1   \n10  0087dd65                    Spring               11                1   \n11  00abe655                      Fall               11                0   \n12  00ae59c9                      Fall               13                0   \n13  00af6387                    Spring               12                0   \n14  00bd4359                    Spring               12                0   \n15  00c0cd71                    Winter                7                0   \n16  00d56d4b                    Spring                5                1   \n17  00d9913d                      Fall               10                1   \n18  00e6167c                    Winter                6                0   \n19  00ebc35d                    Winter               10                0   \n\n   CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n0       Winter             51.0            Fall     16.877316   \n1          NaN              NaN            Fall     14.035590   \n2         Fall             71.0            Fall     16.648696   \n3         Fall             71.0          Summer     18.292347   \n4       Summer              NaN             NaN           NaN   \n5       Winter             50.0          Summer     22.279952   \n6          NaN              NaN            Fall     19.660760   \n7          NaN              NaN            Fall     16.861286   \n8          NaN              NaN          Spring           NaN   \n9       Summer              NaN             NaN           NaN   \n10         NaN              NaN             NaN           NaN   \n11      Summer             66.0             NaN           NaN   \n12         NaN              NaN          Winter     21.079065   \n13         NaN              NaN          Spring     15.544111   \n14         NaN              NaN             NaN           NaN   \n15      Summer             51.0          Spring     29.315775   \n16      Summer             80.0          Spring     17.284504   \n17         NaN              NaN            Fall     19.893157   \n18      Spring             60.0          Winter     30.094649   \n19         NaN              NaN             NaN           NaN   \n\n    Physical-Height  Physical-Weight  ...  BIA-BIA_TBW  PAQ_A-Season  \\\n0             46.00             50.8  ...      32.6909           NaN   \n1             48.00             46.0  ...      27.0552           NaN   \n2             56.50             75.6  ...          NaN           NaN   \n3             56.00             81.6  ...      45.9966           NaN   \n4               NaN              NaN  ...          NaN        Summer   \n5             59.50            112.2  ...      63.1265           NaN   \n6             55.00             84.6  ...      47.2211           NaN   \n7             59.25             84.2  ...      50.4767           NaN   \n8               NaN              NaN  ...          NaN           NaN   \n9               NaN              NaN  ...          NaN           NaN   \n10              NaN              NaN  ...          NaN           NaN   \n11              NaN              NaN  ...          NaN           NaN   \n12            57.75            100.0  ...      56.0118           NaN   \n13            60.00             79.6  ...          NaN           NaN   \n14              NaN              NaN  ...          NaN           NaN   \n15            54.00            121.6  ...          NaN           NaN   \n16            44.00             47.6  ...          NaN           NaN   \n17            55.00             85.6  ...          NaN           NaN   \n18            37.50             60.2  ...      38.7638           NaN   \n19              NaN              NaN  ...          NaN           NaN   \n\n    PAQ_A-PAQ_A_Total  PAQ_C-Season PAQ_C-PAQ_C_Total  SDS-Season  \\\n0                 NaN           NaN               NaN         NaN   \n1                 NaN          Fall             2.340        Fall   \n2                 NaN        Summer             2.170        Fall   \n3                 NaN        Winter             2.451      Summer   \n4                1.04           NaN               NaN         NaN   \n5                 NaN        Spring             4.110      Summer   \n6                 NaN        Winter             3.670      Winter   \n7                 NaN          Fall             1.270         NaN   \n8                 NaN           NaN               NaN         NaN   \n9                 NaN           NaN               NaN         NaN   \n10                NaN           NaN               NaN         NaN   \n11                NaN        Winter             1.100      Winter   \n12                NaN          Fall             3.020        Fall   \n13                NaN        Spring             1.220         NaN   \n14                NaN           NaN               NaN         NaN   \n15                NaN           NaN               NaN      Spring   \n16                NaN           NaN               NaN      Spring   \n17                NaN           NaN               NaN         NaN   \n18                NaN           NaN               NaN      Winter   \n19                NaN           NaN               NaN         NaN   \n\n    SDS-SDS_Total_Raw  SDS-SDS_Total_T PreInt_EduHx-Season  \\\n0                 NaN              NaN                Fall   \n1                46.0             64.0              Summer   \n2                38.0             54.0              Summer   \n3                31.0             45.0              Winter   \n4                 NaN              NaN                 NaN   \n5                40.0             56.0              Spring   \n6                27.0             40.0                Fall   \n7                 NaN              NaN                Fall   \n8                 NaN              NaN              Summer   \n9                 NaN              NaN                 NaN   \n10                NaN              NaN              Spring   \n11               42.0             59.0                Fall   \n12               33.0             47.0                Fall   \n13                NaN              NaN              Spring   \n14                NaN              NaN              Spring   \n15               35.0             50.0              Winter   \n16               37.0             53.0              Spring   \n17                NaN              NaN                Fall   \n18               39.0             55.0              Winter   \n19                NaN              NaN              Winter   \n\n    PreInt_EduHx-computerinternet_hoursday  \n0                                      3.0  \n1                                      0.0  \n2                                      2.0  \n3                                      0.0  \n4                                      NaN  \n5                                      0.0  \n6                                      3.0  \n7                                      2.0  \n8                                      2.0  \n9                                      NaN  \n10                                     NaN  \n11                                     0.0  \n12                                     1.0  \n13                                     NaN  \n14                                     2.0  \n15                                     2.0  \n16                                     0.0  \n17                                     1.0  \n18                                     3.0  \n19                                     2.0  \n\n[20 rows x 59 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Enroll_Season</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-Season</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Season</th>\n      <th>Physical-BMI</th>\n      <th>Physical-Height</th>\n      <th>Physical-Weight</th>\n      <th>...</th>\n      <th>BIA-BIA_TBW</th>\n      <th>PAQ_A-Season</th>\n      <th>PAQ_A-PAQ_A_Total</th>\n      <th>PAQ_C-Season</th>\n      <th>PAQ_C-PAQ_C_Total</th>\n      <th>SDS-Season</th>\n      <th>SDS-SDS_Total_Raw</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-Season</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>Fall</td>\n      <td>5</td>\n      <td>0</td>\n      <td>Winter</td>\n      <td>51.0</td>\n      <td>Fall</td>\n      <td>16.877316</td>\n      <td>46.00</td>\n      <td>50.8</td>\n      <td>...</td>\n      <td>32.6909</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>Summer</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>14.035590</td>\n      <td>48.00</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>27.0552</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>2.340</td>\n      <td>Fall</td>\n      <td>46.0</td>\n      <td>64.0</td>\n      <td>Summer</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>Summer</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Fall</td>\n      <td>16.648696</td>\n      <td>56.50</td>\n      <td>75.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>2.170</td>\n      <td>Fall</td>\n      <td>38.0</td>\n      <td>54.0</td>\n      <td>Summer</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>Winter</td>\n      <td>9</td>\n      <td>0</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Summer</td>\n      <td>18.292347</td>\n      <td>56.00</td>\n      <td>81.6</td>\n      <td>...</td>\n      <td>45.9966</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>2.451</td>\n      <td>Summer</td>\n      <td>31.0</td>\n      <td>45.0</td>\n      <td>Winter</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>Spring</td>\n      <td>18</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>1.04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>001f3379</td>\n      <td>Spring</td>\n      <td>13</td>\n      <td>1</td>\n      <td>Winter</td>\n      <td>50.0</td>\n      <td>Summer</td>\n      <td>22.279952</td>\n      <td>59.50</td>\n      <td>112.2</td>\n      <td>...</td>\n      <td>63.1265</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>4.110</td>\n      <td>Summer</td>\n      <td>40.0</td>\n      <td>56.0</td>\n      <td>Spring</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0038ba98</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>19.660760</td>\n      <td>55.00</td>\n      <td>84.6</td>\n      <td>...</td>\n      <td>47.2211</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>3.670</td>\n      <td>Winter</td>\n      <td>27.0</td>\n      <td>40.0</td>\n      <td>Fall</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0068a485</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>16.861286</td>\n      <td>59.25</td>\n      <td>84.2</td>\n      <td>...</td>\n      <td>50.4767</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>1.270</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0069fbed</td>\n      <td>Summer</td>\n      <td>15</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>Summer</td>\n      <td>19</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>Spring</td>\n      <td>11</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00abe655</td>\n      <td>Fall</td>\n      <td>11</td>\n      <td>0</td>\n      <td>Summer</td>\n      <td>66.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>1.100</td>\n      <td>Winter</td>\n      <td>42.0</td>\n      <td>59.0</td>\n      <td>Fall</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00ae59c9</td>\n      <td>Fall</td>\n      <td>13</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>21.079065</td>\n      <td>57.75</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>56.0118</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.020</td>\n      <td>Fall</td>\n      <td>33.0</td>\n      <td>47.0</td>\n      <td>Fall</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>Spring</td>\n      <td>12</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>15.544111</td>\n      <td>60.00</td>\n      <td>79.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>1.220</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00bd4359</td>\n      <td>Spring</td>\n      <td>12</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00c0cd71</td>\n      <td>Winter</td>\n      <td>7</td>\n      <td>0</td>\n      <td>Summer</td>\n      <td>51.0</td>\n      <td>Spring</td>\n      <td>29.315775</td>\n      <td>54.00</td>\n      <td>121.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>35.0</td>\n      <td>50.0</td>\n      <td>Winter</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>00d56d4b</td>\n      <td>Spring</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>80.0</td>\n      <td>Spring</td>\n      <td>17.284504</td>\n      <td>44.00</td>\n      <td>47.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>37.0</td>\n      <td>53.0</td>\n      <td>Spring</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>00d9913d</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>19.893157</td>\n      <td>55.00</td>\n      <td>85.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>00e6167c</td>\n      <td>Winter</td>\n      <td>6</td>\n      <td>0</td>\n      <td>Spring</td>\n      <td>60.0</td>\n      <td>Winter</td>\n      <td>30.094649</td>\n      <td>37.50</td>\n      <td>60.2</td>\n      <td>...</td>\n      <td>38.7638</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>39.0</td>\n      <td>55.0</td>\n      <td>Winter</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00ebc35d</td>\n      <td>Winter</td>\n      <td>10</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 59 columns</p>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"Some features that are related to the target variable and are not present in the test set. They can act as labels too, either predict them or either predict the output directly","metadata":{}},{"cell_type":"code","source":"train_cols = set(train.columns)\ntest_cols = set(test.columns)\ncolumns_not_in_test = sorted(list(test_cols - train_cols))\ndata_dictionary[data_dictionary['Field'].isin(columns_not_in_test)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-20T04:17:14.692150Z","iopub.execute_input":"2024-11-20T04:17:14.693046Z","iopub.status.idle":"2024-11-20T04:17:14.703588Z","shell.execute_reply.started":"2024-11-20T04:17:14.693006Z","shell.execute_reply":"2024-11-20T04:17:14.702404Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"Empty DataFrame\nColumns: [Instrument, Field, Description, Type, Values, Value Labels]\nIndex: []","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Instrument</th>\n      <th>Field</th>\n      <th>Description</th>\n      <th>Type</th>\n      <th>Values</th>\n      <th>Value Labels</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"markdown","source":"The test dataset doesn't have any PCIAT columns (which is obvious too, since they are used to directly calculate the PII).\r\n\r\nInsight:\r\n\r\nWe should focus on predicting the target from all other features except the PCIAT results.\r\nWe know the target only for two thirds of the samples. The samples without target can perhaps be used for semi-supervised learning.\r\nWe can directly predict sii (this is the value we have to submit), or we can predict PCIAT-PCIAT_Total and then transform this prediction to a sii prediction for submission. As PCIAT-PCIAT_Total is more granular and informative than sii, training to predict PCIAT-PCIAT_Total has the potential to produce a better model.","metadata":{}},{"cell_type":"markdown","source":"Some SII is calculated even when some of PCIAT score is null, this will cause data inconsistency, so let's remove that","metadata":{}},{"cell_type":"code","source":"train['sii'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.260561Z","iopub.execute_input":"2024-11-18T18:48:26.261482Z","iopub.status.idle":"2024-11-18T18:48:26.270410Z","shell.execute_reply.started":"2024-11-18T18:48:26.261408Z","shell.execute_reply":"2024-11-18T18:48:26.269446Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Define the list of PCIAT columns\npciat_columns = [\n    'PCIAT-Season', 'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', \n    'PCIAT-PCIAT_04', 'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', \n    'PCIAT-PCIAT_08', 'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', \n    'PCIAT-PCIAT_12', 'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', \n    'PCIAT-PCIAT_16', 'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', \n    'PCIAT-PCIAT_20', 'PCIAT-PCIAT_Total'\n]\n\n# Step 2: Check for missing values (NaN) in the PCIAT columns\nmissing_pciat_values = train[pciat_columns].isnull().sum()\n\n# Step 3: Display how many PCIAT columns have missing values\nprint(\"Missing values in PCIAT columns:\")\nprint(missing_pciat_values[missing_pciat_values > 0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.271570Z","iopub.execute_input":"2024-11-18T18:48:26.271840Z","iopub.status.idle":"2024-11-18T18:48:26.283259Z","shell.execute_reply.started":"2024-11-18T18:48:26.271813Z","shell.execute_reply":"2024-11-18T18:48:26.282352Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming the dataset is called 'train' and the PCIAT columns are in the following format\npciat_columns = [f'PCIAT-PCIAT_{i:02d}' for i in range(1, 21)]\n\n# Step 1: Count missing values for each row in PCIAT columns\nmissing_pciat_count = train[pciat_columns].isna().sum(axis=1)\nmissing_pciat_count\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.284407Z","iopub.execute_input":"2024-11-18T18:48:26.284750Z","iopub.status.idle":"2024-11-18T18:48:26.303041Z","shell.execute_reply.started":"2024-11-18T18:48:26.284716Z","shell.execute_reply":"2024-11-18T18:48:26.301969Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 2: Define the threshold for keeping rows (5 or fewer missing PCIAT columns)\nthreshold = 5\n\n# Step 3: Filter the train DataFrame to keep only rows where the number of missing PCIAT columns is <= 5\ntrain = train[missing_pciat_count.loc[train.index] <= threshold]\n\n# Step 4: Display the shape of the updated dataset\nprint(f\"Updated dataset shape: {train.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.304605Z","iopub.execute_input":"2024-11-18T18:48:26.305115Z","iopub.status.idle":"2024-11-18T18:48:26.313561Z","shell.execute_reply.started":"2024-11-18T18:48:26.305031Z","shell.execute_reply":"2024-11-18T18:48:26.312575Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check how many rows have any PCIAT column as null\npciat_missing_rows = train[pciat_columns].isnull().sum(axis=1)\n\n# Number of rows with at least one null PCIAT value\nrows_with_null_pciat = (pciat_missing_rows > 0).sum()\nprint(f\"Number of rows with at least one missing PCIAT value: {rows_with_null_pciat}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.316855Z","iopub.execute_input":"2024-11-18T18:48:26.317865Z","iopub.status.idle":"2024-11-18T18:48:26.326290Z","shell.execute_reply.started":"2024-11-18T18:48:26.317828Z","shell.execute_reply":"2024-11-18T18:48:26.325268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count missing values per PCIAT column\nmissing_values_per_column = train[pciat_columns].isna().sum()\n\n# Sort the missing values for better visibility\nmissing_values_per_column = missing_values_per_column.sort_values(ascending=False)\n\n# Display the missing values count per column\nprint(missing_values_per_column)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.327715Z","iopub.execute_input":"2024-11-18T18:48:26.328127Z","iopub.status.idle":"2024-11-18T18:48:26.337766Z","shell.execute_reply.started":"2024-11-18T18:48:26.328082Z","shell.execute_reply":"2024-11-18T18:48:26.336835Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot missing values per PCIAT column\nplt.figure(figsize=(12, 6))\nmissing_values_per_column.plot(kind='bar', color='skyblue')\nplt.title('Missing Values per PCIAT Column')\nplt.xlabel('PCIAT Columns')\nplt.ylabel('Number of Missing Values')\nplt.xticks(rotation=90)\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.338811Z","iopub.execute_input":"2024-11-18T18:48:26.339098Z","iopub.status.idle":"2024-11-18T18:48:26.689873Z","shell.execute_reply.started":"2024-11-18T18:48:26.339071Z","shell.execute_reply":"2024-11-18T18:48:26.688891Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of PCIAT column names (before imputation)\npciat_columns = [\n    'PCIAT-PCIAT_01', 'PCIAT-PCIAT_02', 'PCIAT-PCIAT_03', 'PCIAT-PCIAT_04', \n    'PCIAT-PCIAT_05', 'PCIAT-PCIAT_06', 'PCIAT-PCIAT_07', 'PCIAT-PCIAT_08', \n    'PCIAT-PCIAT_09', 'PCIAT-PCIAT_10', 'PCIAT-PCIAT_11', 'PCIAT-PCIAT_12', \n    'PCIAT-PCIAT_13', 'PCIAT-PCIAT_14', 'PCIAT-PCIAT_15', 'PCIAT-PCIAT_16', \n    'PCIAT-PCIAT_17', 'PCIAT-PCIAT_18', 'PCIAT-PCIAT_19', 'PCIAT-PCIAT_20'\n]\n\n# Mapping of PCIAT columns to the target names\npciat_column_mapping = {\n    'PCIAT-PCIAT_01': 'disobey_time_limits',\n    'PCIAT-PCIAT_02': 'neglect_chores',\n    'PCIAT-PCIAT_03': 'prefer_online_over_family',\n    'PCIAT-PCIAT_04': 'form_online_relationships',\n    'PCIAT-PCIAT_05': 'parent_complains_time',\n    'PCIAT-PCIAT_06': 'grades_suffer',\n    'PCIAT-PCIAT_07': 'check_email_first',\n    'PCIAT-PCIAT_08': 'withdrawn_from_others',\n    'PCIAT-PCIAT_09': 'defensive_secretive',\n    'PCIAT-PCIAT_10': 'sneaking_online',\n    'PCIAT-PCIAT_11': 'alone_in_room_computing',\n    'PCIAT-PCIAT_12': 'strange_calls_online_friends',\n    'PCIAT-PCIAT_13': 'annoyed_if_bothered',\n    'PCIAT-PCIAT_14': 'more_tired_fatigued',\n    'PCIAT-PCIAT_15': 'preoccupied_with_online',\n    'PCIAT-PCIAT_16': 'tantrums_over_interference',\n    'PCIAT-PCIAT_17': 'online_over_hobbies',\n    'PCIAT-PCIAT_18': 'angry_at_time_limits',\n    'PCIAT-PCIAT_19': 'online_over_friends',\n    'PCIAT-PCIAT_20': 'mood_improves_online'\n}\n\n# Count missing values per PCIAT column\nmissing_values_per_column = train[pciat_columns].isna().sum()\n\n# Sort the missing values for better visibility\nmissing_values_per_column = missing_values_per_column.sort_values(ascending=False)\n\n# Display the missing values count per column\nprint(\"Missing Values Count per PCIAT Column:\")\nprint(missing_values_per_column)\n\n# Mapping the columns from PCIAT columns to their corresponding target names\nmapped_missing_values = missing_values_per_column.index.to_series().map(pciat_column_mapping)\n\n# Print the columns and their corresponding target names with missing counts\nfor pciat_column, missing_count in missing_values_per_column.items():\n    target_column = pciat_column_mapping[pciat_column]\n    print(f\"Target Column: {target_column} (PCIAT Column: {pciat_column}) - Missing Values: {missing_count}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.691780Z","iopub.execute_input":"2024-11-18T18:48:26.692197Z","iopub.status.idle":"2024-11-18T18:48:26.707929Z","shell.execute_reply.started":"2024-11-18T18:48:26.692151Z","shell.execute_reply":"2024-11-18T18:48:26.706680Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Define the column mapping\ncolumn_mapping = {\n    'PCIAT-PCIAT_01': 'disobey_time_limits',\n    'PCIAT-PCIAT_02': 'neglect_chores',\n    'PCIAT-PCIAT_03': 'prefer_online_over_family',\n    'PCIAT-PCIAT_04': 'form_online_relationships',\n    'PCIAT-PCIAT_05': 'parent_complains_time',\n    'PCIAT-PCIAT_06': 'grades_suffer',\n    'PCIAT-PCIAT_07': 'check_email_first',\n    'PCIAT-PCIAT_08': 'withdrawn_from_others',\n    'PCIAT-PCIAT_09': 'defensive_secretive',\n    'PCIAT-PCIAT_10': 'sneaking_online',\n    'PCIAT-PCIAT_11': 'alone_in_room_computing',\n    'PCIAT-PCIAT_12': 'strange_calls_online_friends',\n    'PCIAT-PCIAT_13': 'annoyed_if_bothered',\n    'PCIAT-PCIAT_14': 'more_tired_fatigued',\n    'PCIAT-PCIAT_15': 'preoccupied_with_online',\n    'PCIAT-PCIAT_16': 'tantrums_over_interference',\n    'PCIAT-PCIAT_17': 'online_over_hobbies',\n    'PCIAT-PCIAT_18': 'angry_at_time_limits',\n    'PCIAT-PCIAT_19': 'online_over_friends',\n    'PCIAT-PCIAT_20': 'mood_improves_online'\n}\n\n# Rename the columns in the DataFrame\ntrain.rename(columns=column_mapping, inplace=True)\n\n# Display the first few rows of the renamed DataFrame\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T18:48:26.709218Z","iopub.execute_input":"2024-11-18T18:48:26.709593Z","iopub.status.idle":"2024-11-18T18:48:26.748086Z","shell.execute_reply.started":"2024-11-18T18:48:26.709556Z","shell.execute_reply":"2024-11-18T18:48:26.747056Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to calculate correlation of PCIAT columns with selected features\ndef get_correlations_with_pciat(pciat_columns, selected_features):\n    correlation_results = {}\n    \n    for pciat_column in pciat_columns:\n        correlations = {}\n        for feature in selected_features:\n            # Calculate the correlation for each PCIAT column with each selected feature\n            correlation = train[pciat_column].corr(train[feature])\n            correlations[feature] = correlation\n        correlation_results[pciat_column] = correlations\n    \n    return correlation_results\n\n# Extract the PCIAT columns from the column_mapping dictionary (values)\npciat_columns = list(column_mapping.values())\n\n# Selected features to correlate with PCIAT columns\nselected_features = [\n    'Basic_Demos-Age', 'Basic_Demos-Sex', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'\n]\n\n# Getting correlation results for each PCIAT column\ncorrelation_results = get_correlations_with_pciat(pciat_columns, selected_features)\n\n# Displaying the correlation results\nfor pciat_column, correlations in correlation_results.items():\n    print(f\"Correlations for {pciat_column}:\")\n    for feature, corr_value in correlations.items():\n        print(f\"  {feature}: {corr_value}\")\n    print()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.749388Z","iopub.execute_input":"2024-11-18T18:48:26.750483Z","iopub.status.idle":"2024-11-18T18:48:26.788659Z","shell.execute_reply.started":"2024-11-18T18:48:26.750408Z","shell.execute_reply":"2024-11-18T18:48:26.787552Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.789884Z","iopub.execute_input":"2024-11-18T18:48:26.790204Z","iopub.status.idle":"2024-11-18T18:48:26.813894Z","shell.execute_reply.started":"2024-11-18T18:48:26.790169Z","shell.execute_reply":"2024-11-18T18:48:26.812813Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n\n# Initialize KNNImputer\nknn_imputer = KNNImputer(n_neighbors=5)\n\n# Columns and their correlated features for imputation\n# Updated correlation map based on correlation values > 0.2\n\ncorrelation_map = {\n    'disobey_time_limits': ['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'neglect_chores': ['PreInt_EduHx-computerinternet_hoursday', 'SDS-SDS_Total_T'],\n    'prefer_online_over_family': ['Basic_Demos-Age', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'form_online_relationships': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'parent_complains_time': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'grades_suffer': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'check_email_first': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'withdrawn_from_others': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'defensive_secretive': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'sneaking_online': ['PreInt_EduHx-computerinternet_hoursday'],\n    'alone_in_room_computing': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'strange_calls_online_friends': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'annoyed_if_bothered': ['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'more_tired_fatigued': ['Basic_Demos-Age', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'preoccupied_with_online': ['Basic_Demos-Age', 'SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'tantrums_over_interference': ['SDS-SDS_Total_T'],\n    'online_over_hobbies': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'angry_at_time_limits': ['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday'],\n    'online_over_friends': ['Basic_Demos-Age', 'PreInt_EduHx-computerinternet_hoursday'],\n    'mood_improves_online': ['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']\n}\n\n# Create a dictionary to store imputed records and the correlation features used\nimputed_records = {}\n\n# Impute missing values for each column\nfor column, correlated_columns in correlation_map.items():\n    # Select the relevant columns for imputation\n    selected_columns = [column] + correlated_columns\n    imputed_values = knn_imputer.fit_transform(train[selected_columns])\n    \n    # Identify the rows where imputation occurred (NaN values replaced)\n    imputed_indices = train[column].isna()  # Rows where values were NaN\n    \n    # Count the number of imputed values\n    n_imputed = imputed_indices.sum()  # Count of NaN values replaced\n    \n    # Store the imputed values and correlation features used\n    imputed_records[column] = {\n        'imputed_count': n_imputed,\n        'correlated_features': correlated_columns,\n        'updated_rows': imputed_values[:, 0],  # Only update the imputed column\n        'imputed_indices': imputed_indices  # Store indices of imputed rows\n    }\n    \n    # Update the original column with imputed values for NaNs\n    train[column] = imputed_values[:, 0]  # Only update the imputed column\n\n# Print imputed records and the number of imputed rows, with imputed row indices\nfor column, data in imputed_records.items():\n    print(f\"Column: {column}\")\n    print(f\"Imputed records count: {data['imputed_count']}\")\n    print(f\"Correlation features used: {data['correlated_features']}\")\n    \n    # Get indices of imputed rows and display the first 5 updated rows (indices)\n    imputed_row_indices = data['imputed_indices'].to_numpy().nonzero()[0]  # Convert to NumPy array and use nonzero\n    \n    print(f\"Imputed rows indices (sample): {imputed_row_indices[:5]}\")  # Show first 5 imputed row indices\n    print(f\"Updated rows (sample): {train.iloc[imputed_row_indices[:5]][column].values}\")  # Show first 5 imputed values\n    print(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:26.817567Z","iopub.execute_input":"2024-11-18T18:48:26.818005Z","iopub.status.idle":"2024-11-18T18:48:27.638240Z","shell.execute_reply.started":"2024-11-18T18:48:26.817968Z","shell.execute_reply":"2024-11-18T18:48:27.636125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:27.639784Z","iopub.execute_input":"2024-11-18T18:48:27.640219Z","iopub.status.idle":"2024-11-18T18:48:27.793883Z","shell.execute_reply.started":"2024-11-18T18:48:27.640173Z","shell.execute_reply":"2024-11-18T18:48:27.792851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:27.795584Z","iopub.execute_input":"2024-11-18T18:48:27.795986Z","iopub.status.idle":"2024-11-18T18:48:27.802202Z","shell.execute_reply.started":"2024-11-18T18:48:27.795940Z","shell.execute_reply":"2024-11-18T18:48:27.801152Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for null values in the renamed columns\nnull_counts = train.isnull().sum()\n\n# Filter for columns that have null values\ncolumns_with_nulls = null_counts[null_counts > 0]\n\n# Print the count of null values for each column with nulls\nprint(f\"Columns with null values:\\n{columns_with_nulls}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:27.803484Z","iopub.execute_input":"2024-11-18T18:48:27.803838Z","iopub.status.idle":"2024-11-18T18:48:27.818964Z","shell.execute_reply.started":"2024-11-18T18:48:27.803791Z","shell.execute_reply":"2024-11-18T18:48:27.817900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We have cleared all the nan values for PCIAT columns now","metadata":{}},{"cell_type":"code","source":"# List of renamed PCIAT columns\npciat_columns = [\n    'disobey_time_limits', 'neglect_chores', 'prefer_online_over_family', \n    'form_online_relationships', 'parent_complains_time', 'grades_suffer', \n    'check_email_first', 'withdrawn_from_others', 'defensive_secretive', \n    'sneaking_online', 'alone_in_room_computing', 'strange_calls_online_friends', \n    'annoyed_if_bothered', 'more_tired_fatigued', 'preoccupied_with_online', \n    'tantrums_over_interference', 'online_over_hobbies', 'angry_at_time_limits', \n    'online_over_friends', 'mood_improves_online'\n]\n\n# Step 1: Recalculate PCIAT Total (sum of the 20 columns)\ntrain['PCIAT_total'] = train[pciat_columns].sum(axis=1)\n\n# Step 2: Recalculate the SII (Severity Impairment Index) with numeric values\ndef calculate_sii(pciat_total):\n    if pciat_total >= 0 and pciat_total <= 30:\n        return 0  # None\n    elif pciat_total >= 31 and pciat_total <= 49:\n        return 1  # Mild\n    elif pciat_total >= 50 and pciat_total <= 79:\n        return 2  # Moderate\n    elif pciat_total >= 80 and pciat_total <= 100:\n        return 3  # Severe\n    else:\n        return -1  # Invalid, in case the total exceeds 100\n\n# Apply the SII calculation to the PCIAT_total column\ntrain['sii'] = train['PCIAT_total'].apply(calculate_sii)\n\n# Step 3: Check for any invalid SII (-1 values)\ninvalid_sii_rows = train[train['sii'] == -1]\nif not invalid_sii_rows.empty:\n    print(f\"Rows with invalid SII (-1):\\n{invalid_sii_rows[['PCIAT_total', 'sii']].head()}\")  # Display first few invalid rows\nelse:\n    print(\"No invalid SII values (-1) found.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:27.820126Z","iopub.execute_input":"2024-11-18T18:48:27.820474Z","iopub.status.idle":"2024-11-18T18:48:27.840333Z","shell.execute_reply.started":"2024-11-18T18:48:27.820419Z","shell.execute_reply":"2024-11-18T18:48:27.839364Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Remove rows with invalid SII (-1 values)\ntrain = train[train['sii'] != -1]\n\n# Step 4: Check the overall distribution of SII\nplt.figure(figsize=(10, 6))\nplt.hist(train['sii'], bins=4, edgecolor='black')  # Adjust bins for SII values (0-3)\nplt.title('Overall SII Distribution After Removing Invalid Entries')\nplt.xlabel('SII Value')\nplt.ylabel('Frequency')\nplt.xticks([0, 1, 2, 3], ['None', 'Mild', 'Moderate', 'Severe'])  # Label x-axis with SII categories\nplt.show()\n\n# Display the updated dataframe with PCIAT_total and SII for reference\ntrain[['PCIAT_total', 'sii']].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:27.841419Z","iopub.execute_input":"2024-11-18T18:48:27.841754Z","iopub.status.idle":"2024-11-18T18:48:28.065121Z","shell.execute_reply.started":"2024-11-18T18:48:27.841722Z","shell.execute_reply":"2024-11-18T18:48:28.064137Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# # Assuming train is your DataFrame containing the relevant data\n\n# # Step 1: Automatically generate the list of pciat column names (20 columns)\n# PCIAT_cols = [f'PCIAT-PCIAT_{i+1:02d}' for i in range(20)]  # PCIAT-PCIAT_01 to PCIAT-PCIAT_20\n\n# # Step 2: Define the recalculate_sii function\n# def recalculate_sii(row):\n#     if pd.isna(row['PCIAT-PCIAT_Total']):\n#         return np.nan\n#     max_possible = row['PCIAT-PCIAT_Total'] + row[PCIAT_cols].isna().sum() * 5\n#     if row['PCIAT-PCIAT_Total'] <= 30 and max_possible <= 30:\n#         return 0\n#     elif 31 <= row['PCIAT-PCIAT_Total'] <= 49 and max_possible <= 49:\n#         return 1\n#     elif 50 <= row['PCIAT-PCIAT_Total'] <= 79 and max_possible <= 79:\n#         return 2\n#     elif row['PCIAT-PCIAT_Total'] >= 80 and max_possible >= 80:\n#         return 3\n#     return np.nan\n\n# # Step 3: Calculate pciat_total, mark as NaN if any pciat value is NaN\n# train['PCIAT-PCIAT_Total'] = train[PCIAT_cols].apply(\n#     lambda x: x.sum() if x.notna().all() else np.nan, axis=1\n# )\n\n# # Step 4: Count rows with PCIAT-PCIAT_Total as NaN\n# nan_count = train['PCIAT-PCIAT_Total'].isna().sum()\n# print(f\"Number of rows with NaN in PCIAT-PCIAT_Total: {nan_count}\")\n\n# # Step 5: Drop rows where PCIAT-PCIAT_Total is NaN\n# train = train.dropna(subset=['PCIAT-PCIAT_Total'])\n\n# # Step 6: Recalculate SII using the recalculate_sii function on the cleaned data\n# train['recalc_sii'] = train.apply(recalculate_sii, axis=1)\n\n# # Step 7: Visualize the SII distribution\n# plt.figure(figsize=(10, 6))\n# plt.hist(train['recalc_sii'], bins=20, edgecolor='black')\n# plt.title('Recalculated SII Distribution After Data Cleaning')\n# plt.xlabel('SII Value')\n# plt.ylabel('Frequency')\n# plt.show()\n\n# # Show the first few rows of the cleaned data with recalc_sii\n# train.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.066815Z","iopub.execute_input":"2024-11-18T18:48:28.067403Z","iopub.status.idle":"2024-11-18T18:48:28.072566Z","shell.execute_reply.started":"2024-11-18T18:48:28.067355Z","shell.execute_reply":"2024-11-18T18:48:28.071657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# train['recalc_sii'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.073727Z","iopub.execute_input":"2024-11-18T18:48:28.074015Z","iopub.status.idle":"2024-11-18T18:48:28.087087Z","shell.execute_reply.started":"2024-11-18T18:48:28.073983Z","shell.execute_reply":"2024-11-18T18:48:28.086102Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"only use the corrected SII. I will only use total scores if all PCIAT_cols have non-NA values (all questions of the Parent-Child Internet Addiction Test have been answered).","metadata":{}},{"cell_type":"code","source":"# train['sii'] = train['recalc_sii']\n\n# train.drop(columns='recalc_sii', inplace=True)\n# train.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.088327Z","iopub.execute_input":"2024-11-18T18:48:28.088698Z","iopub.status.idle":"2024-11-18T18:48:28.097443Z","shell.execute_reply.started":"2024-11-18T18:48:28.088650Z","shell.execute_reply":"2024-11-18T18:48:28.096449Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\n\n# Step 1: Calculate SII counts and percentages\nsii_counts = train['sii'].value_counts().reset_index()\nsii_counts.columns = ['sii', 'count']  # Renaming columns for clarity\ntotal = sii_counts['count'].sum()\nsii_counts['percentage'] = (sii_counts['count'] / total) * 100\n\n# Step 2: Create the subplots for visualization\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# SII Distribution\nsns.barplot(x='sii', y='count', data=sii_counts, palette='Blues_d', ax=axes[0])\naxes[0].set_title('Distribution of Recalculated Severity Impairment Index (SII)', fontsize=14)\nfor p in axes[0].patches:\n    height = p.get_height()\n    percentage = sii_counts.loc[sii_counts['count'] == height, 'percentage'].values[0]\n    axes[0].text(\n        p.get_x() + p.get_width() / 2,\n        height + 5, f'{int(height)} ({percentage:.1f}%)',\n        ha=\"center\", fontsize=12\n    )\n\n# PCIAT_Total for complete responses (those without NaN)\nsns.histplot(train['PCIAT-PCIAT_Total'].dropna(), bins=20, ax=axes[1])\naxes[1].set_title('Distribution of PCIAT_Total for Complete Responses', fontsize=14)\naxes[1].set_xlabel('PCIAT_Total')\n\n# Adjust layout for better presentation\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.098776Z","iopub.execute_input":"2024-11-18T18:48:28.099099Z","iopub.status.idle":"2024-11-18T18:48:28.802699Z","shell.execute_reply.started":"2024-11-18T18:48:28.099067Z","shell.execute_reply":"2024-11-18T18:48:28.801539Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# \"\"\"Analyze SII distribution and class balance\"\"\"\nsii_dist = train['sii'].value_counts()\nprint(sii_dist)\ntrain.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.804283Z","iopub.execute_input":"2024-11-18T18:48:28.804601Z","iopub.status.idle":"2024-11-18T18:48:28.812243Z","shell.execute_reply.started":"2024-11-18T18:48:28.804571Z","shell.execute_reply":"2024-11-18T18:48:28.811186Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Remove records having missing sii","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.813348Z","iopub.execute_input":"2024-11-18T18:48:28.813635Z","iopub.status.idle":"2024-11-18T18:48:28.844713Z","shell.execute_reply.started":"2024-11-18T18:48:28.813605Z","shell.execute_reply":"2024-11-18T18:48:28.843807Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Step 1: Get the value counts for the recalculated 'recalc_sii' column\nvalue_counts_recalc_sii = train['sii'].value_counts()\n\n# Print value counts (Optional, for verification)\nprint(value_counts_recalc_sii)\n\n# Step 2: Create the Pie Chart for recalculated SII (recalc_sii)\nplt.figure(figsize=(8, 6))\nplt.pie(value_counts_recalc_sii, labels=value_counts_recalc_sii.index, autopct='%1.1f%%', startangle=140)\nplt.title('Class Distribution in the Recalculated Severity Impairment Index (recalc_sii)')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.846067Z","iopub.execute_input":"2024-11-18T18:48:28.846411Z","iopub.status.idle":"2024-11-18T18:48:28.970897Z","shell.execute_reply.started":"2024-11-18T18:48:28.846363Z","shell.execute_reply":"2024-11-18T18:48:28.969883Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Set the size for the plot\nplt.figure(figsize=(15, 10))\n\n# Plot histograms for each renamed PCIAT column\nfor i, column in enumerate(column_mapping.values()):\n    plt.subplot(5, 4, i+1)\n    sns.histplot(train[column].dropna(), bins=20, kde=True)\n    plt.title(f'Distribution of {column}', fontsize=12)\n    plt.tight_layout()\n\nplt.show()\n# Modify this","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:28.972146Z","iopub.execute_input":"2024-11-18T18:48:28.972579Z","iopub.status.idle":"2024-11-18T18:48:37.706448Z","shell.execute_reply.started":"2024-11-18T18:48:28.972532Z","shell.execute_reply":"2024-11-18T18:48:37.705529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert column_mapping values to a list and concatenate with 'sii'\npciat_columns = list(column_mapping.values())  # Convert dict_values to list\n\n# Compute correlation\ncorrelation = train[pciat_columns + ['sii']].corr()\n\n# Extract the correlations with 'sii'\nsii_correlation = correlation['sii'].sort_values(ascending=False)\n\n# Show the correlation values\nprint(sii_correlation)\n\n# Visualize the correlations with a heatmap\nplt.figure(figsize=(10, 6))\n# Select the correlation values of 'sii' with each PCIAT column\nsns.heatmap(correlation.loc[pciat_columns, ['sii']], annot=True, cmap='coolwarm', vmin=-1, vmax=1)\nplt.title('Correlation between PCIAT columns and Severity Impairment Index (sii)', fontsize=14)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-11-18T18:48:37.707974Z","iopub.execute_input":"2024-11-18T18:48:37.708374Z","iopub.status.idle":"2024-11-18T18:48:38.363046Z","shell.execute_reply.started":"2024-11-18T18:48:37.708329Z","shell.execute_reply":"2024-11-18T18:48:38.362032Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the figure size\nplt.figure(figsize=(15, 10))\n\n# Scatter plot for each PCIAT column vs recalc_sii\nfor i, column in enumerate(pciat_columns):\n    plt.subplot(5, 4, i+1)\n    sns.scatterplot(x=train[column], y=train['sii'])\n    plt.title(f'{column} vs recalc_sii', fontsize=12)\n    plt.tight_layout()\n\nplt.show()\n# this has to be modified","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:38.364485Z","iopub.execute_input":"2024-11-18T18:48:38.364871Z","iopub.status.idle":"2024-11-18T18:48:45.929930Z","shell.execute_reply.started":"2024-11-18T18:48:38.364826Z","shell.execute_reply":"2024-11-18T18:48:45.928828Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Cleaning and understanding demographic fields","metadata":{}},{"cell_type":"code","source":"print(train['Basic_Demos-Enroll_Season'].unique())\nprint(train['Basic_Demos-Age'].unique())\nprint(train['Basic_Demos-Sex'].unique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:45.931135Z","iopub.execute_input":"2024-11-18T18:48:45.931441Z","iopub.status.idle":"2024-11-18T18:48:45.938007Z","shell.execute_reply.started":"2024-11-18T18:48:45.931411Z","shell.execute_reply":"2024-11-18T18:48:45.937099Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values\nprint(train[['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex']].isna().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:45.939437Z","iopub.execute_input":"2024-11-18T18:48:45.940004Z","iopub.status.idle":"2024-11-18T18:48:45.952176Z","shell.execute_reply.started":"2024-11-18T18:48:45.939969Z","shell.execute_reply":"2024-11-18T18:48:45.951140Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Summary statistics\nprint(train['Basic_Demos-Age'].describe())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:45.953185Z","iopub.execute_input":"2024-11-18T18:48:45.953502Z","iopub.status.idle":"2024-11-18T18:48:45.966363Z","shell.execute_reply.started":"2024-11-18T18:48:45.953446Z","shell.execute_reply":"2024-11-18T18:48:45.965111Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the minimum and maximum ages\nage_min = train['Basic_Demos-Age'].min()\nage_max = train['Basic_Demos-Age'].max()\n\nprint(f\"Age range: {age_min} - {age_max}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:45.967891Z","iopub.execute_input":"2024-11-18T18:48:45.968411Z","iopub.status.idle":"2024-11-18T18:48:45.978520Z","shell.execute_reply.started":"2024-11-18T18:48:45.968363Z","shell.execute_reply":"2024-11-18T18:48:45.977489Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.histplot(train['Basic_Demos-Age'], kde=True)\nplt.title('Age Distribution of Participants')\nplt.xlabel('Age')\nplt.ylabel('Frequency')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:45.986756Z","iopub.execute_input":"2024-11-18T18:48:45.987185Z","iopub.status.idle":"2024-11-18T18:48:46.320925Z","shell.execute_reply.started":"2024-11-18T18:48:45.987152Z","shell.execute_reply":"2024-11-18T18:48:46.319940Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation between age and 'sii'\nage_correlation = train[['Basic_Demos-Age', 'sii']].corr()\nprint(f\"Correlation between Age and sii: {age_correlation.loc['Basic_Demos-Age', 'sii']}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.322272Z","iopub.execute_input":"2024-11-18T18:48:46.322698Z","iopub.status.idle":"2024-11-18T18:48:46.329779Z","shell.execute_reply.started":"2024-11-18T18:48:46.322651Z","shell.execute_reply":"2024-11-18T18:48:46.328769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Count plot for Basic_Demos-Sex\nsns.countplot(data=train, x='Basic_Demos-Sex')\nplt.title('Distribution of Participants by Sex')\nplt.xlabel('Sex (0=Male, 1=Female)')\nplt.ylabel('Count')\nplt.show()\n\n# Count plot for Basic_Demos-Enroll_Season\nsns.countplot(data=train, x='Basic_Demos-Enroll_Season')\nplt.title('Distribution of Participants by Enrollment Season')\nplt.xlabel('Enroll Season')\nplt.ylabel('Count')\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.331250Z","iopub.execute_input":"2024-11-18T18:48:46.331773Z","iopub.status.idle":"2024-11-18T18:48:46.645410Z","shell.execute_reply.started":"2024-11-18T18:48:46.331727Z","shell.execute_reply":"2024-11-18T18:48:46.644312Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy import stats\n\n# Assuming 'train' is your DataFrame and 'Basic_Demos-Sex' is the column for Sex, 'sii' is the target\ngroup1 = train[train['Basic_Demos-Sex'] == 0]['sii']\ngroup2 = train[train['Basic_Demos-Sex'] == 1]['sii']\n\n# Perform t-test\nt_stat, p_value = stats.ttest_ind(group1, group2)\n\nprint(f\"T-statistic: {t_stat}, P-value: {p_value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.646635Z","iopub.execute_input":"2024-11-18T18:48:46.646928Z","iopub.status.idle":"2024-11-18T18:48:46.659429Z","shell.execute_reply.started":"2024-11-18T18:48:46.646897Z","shell.execute_reply":"2024-11-18T18:48:46.658366Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sex is an important feature to consider for building your model since it has a significant relationship with the target variable sii","metadata":{}},{"cell_type":"code","source":"# Perform ANOVA for 'Enrollment Season' vs 'sii'\nf_stat, p_value = stats.f_oneway(\n    train[train['Basic_Demos-Enroll_Season'] == 'Fall']['sii'],\n    train[train['Basic_Demos-Enroll_Season'] == 'Spring']['sii'],\n    train[train['Basic_Demos-Enroll_Season'] == 'Summer']['sii'],\n    train[train['Basic_Demos-Enroll_Season'] == 'Winter']['sii']\n)\n\nprint(f\"F-statistic: {f_stat}, P-value: {p_value}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.660668Z","iopub.execute_input":"2024-11-18T18:48:46.660968Z","iopub.status.idle":"2024-11-18T18:48:46.675447Z","shell.execute_reply.started":"2024-11-18T18:48:46.660939Z","shell.execute_reply":"2024-11-18T18:48:46.674331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Therefore, Enrollment Season does not have a significant impact on sii at the 5% significance level.","metadata":{}},{"cell_type":"code","source":"# Drop 'Enrollment Season' column from the training dataframe\ntrain = train.drop(columns=['Basic_Demos-Enroll_Season'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.676586Z","iopub.execute_input":"2024-11-18T18:48:46.676863Z","iopub.status.idle":"2024-11-18T18:48:46.683659Z","shell.execute_reply.started":"2024-11-18T18:48:46.676835Z","shell.execute_reply":"2024-11-18T18:48:46.682706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate Pearson's correlation between 'age' and 'sii'\nage_corr = train['Basic_Demos-Age'].corr(train['sii'])\nprint(f\"Pearson correlation between age and sii: {age_corr}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.685044Z","iopub.execute_input":"2024-11-18T18:48:46.685442Z","iopub.status.idle":"2024-11-18T18:48:46.693979Z","shell.execute_reply.started":"2024-11-18T18:48:46.685397Z","shell.execute_reply":"2024-11-18T18:48:46.692950Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def process_age(df):\n    # Define bins for age grouping\n    bins = [0, 5, 12, 15, 18, 22]  # Adjusted to start from 0 as 'Child' should be 0-5\n    labels = ['Child', 'Early Teen', 'Teen', 'Young Adult', 'Adult']\n    \n    # Create 'age_group' by categorizing 'Basic_Demos-Age'\n    df['age_group'] = pd.cut(df['Basic_Demos-Age'], \n                             bins=bins, \n                             labels=labels, \n                             right=True,  # Include the upper bound of each bin\n                             include_lowest=True)  # Include the lower bound for the first group\n    \n    # Check if any NaN values exist in the 'age_group' column\n    if df['age_group'].isna().sum() > 0:\n        print(f\"Warning: There are {df['age_group'].isna().sum()} NaN values in 'age_group'.\")\n\n    return df\n\n# Apply the function to the train DataFrame to create and process the 'age_group' column\ntrain = process_age(train)\n\n# Check if the 'age_group' column is now present\nprint(\"Columns in processed DataFrame:\", train.columns)\n\n# Check the first few rows to confirm the 'age_group' assignment\nprint(train[['Basic_Demos-Age', 'age_group']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.695742Z","iopub.execute_input":"2024-11-18T18:48:46.696149Z","iopub.status.idle":"2024-11-18T18:48:46.710250Z","shell.execute_reply.started":"2024-11-18T18:48:46.696104Z","shell.execute_reply":"2024-11-18T18:48:46.709190Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.711572Z","iopub.execute_input":"2024-11-18T18:48:46.711890Z","iopub.status.idle":"2024-11-18T18:48:46.742309Z","shell.execute_reply.started":"2024-11-18T18:48:46.711860Z","shell.execute_reply":"2024-11-18T18:48:46.741332Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for NaN values in the 'age_group' column\nnan_count = train['age_group'].isna().sum()\nprint(f\"NaN values in 'age_group': {nan_count}\")\n\n# Optionally, check the rows with NaN values (if any)\nif nan_count > 0:\n    print(train[train['age_group'].isna()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.743718Z","iopub.execute_input":"2024-11-18T18:48:46.744442Z","iopub.status.idle":"2024-11-18T18:48:46.753383Z","shell.execute_reply.started":"2024-11-18T18:48:46.744393Z","shell.execute_reply":"2024-11-18T18:48:46.752395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\noutput_dir = '/kaggle/working/child-mind-institute-problematic-internet-use'\nos.makedirs(output_dir, exist_ok=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.754730Z","iopub.execute_input":"2024-11-18T18:48:46.755283Z","iopub.status.idle":"2024-11-18T18:48:46.764253Z","shell.execute_reply.started":"2024-11-18T18:48:46.755249Z","shell.execute_reply":"2024-11-18T18:48:46.763181Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# List of columns to remove\ncolumns_to_remove = [\n    \"CGAS-Season\", \"CGAS-CGAS_Score\",\n    \"Physical-Season\", \"Physical-BMI\", \"Physical-Height\", \"Physical-Weight\",\n    \"Physical-Waist_Circumference\", \"Physical-Diastolic_BP\", \"Physical-HeartRate\",\n    \"Physical-Systolic_BP\", \"Fitness_Endurance-Season\", \"Fitness_Endurance-Max_Stage\",\n    \"Fitness_Endurance-Time_Mins\", \"Fitness_Endurance-Time_Sec\",\n    \"FGC-Season\", \"FGC-FGC_CU\", \"FGC-FGC_CU_Zone\", \"FGC-FGC_GSND\",\n    \"FGC-FGC_GSND_Zone\", \"FGC-FGC_GSD\", \"FGC-FGC_GSD_Zone\", \"FGC-FGC_PU\",\n    \"FGC-FGC_PU_Zone\", \"FGC-FGC_SRL\", \"FGC-FGC_SRL_Zone\", \"FGC-FGC_SRR\",\n    \"FGC-FGC_SRR_Zone\", \"FGC-FGC_TL\", \"FGC-FGC_TL_Zone\",\n    \"BIA-Season\", \"BIA-BIA_Activity_Level_num\", \"BIA-BIA_BMC\",\n    \"BIA-BIA_BMI\", \"BIA-BIA_BMR\", \"BIA-BIA_DEE\", \"BIA-BIA_ECW\",\n    \"BIA-BIA_FFM\", \"BIA-BIA_FFMI\", \"BIA-BIA_FMI\", \"BIA-BIA_Fat\",\n    \"BIA-BIA_Frame_num\", \"BIA-BIA_ICW\", \"BIA-BIA_LDM\",\n    \"BIA-BIA_LST\", \"BIA-BIA_SMM\", \"BIA-BIA_TBW\",\n    \"PAQ_A-Season\", \"PAQ_A-PAQ_A_Total\",\n    \"PAQ_C-Season\", \"PAQ_C-PAQ_C_Total\",\n    \"PCIAT-Season\", \"PCIAT-PCIAT_01\", \"PCIAT-PCIAT_02\", \"PCIAT-PCIAT_03\",\n    \"PCIAT-PCIAT_04\", \"PCIAT-PCIAT_05\", \"PCIAT-PCIAT_06\", \"PCIAT-PCIAT_07\",\n    \"PCIAT-PCIAT_08\", \"PCIAT-PCIAT_09\", \"PCIAT-PCIAT_10\", \"PCIAT-PCIAT_11\",\n    \"PCIAT-PCIAT_12\", \"PCIAT-PCIAT_13\", \"PCIAT-PCIAT_14\", \"PCIAT-PCIAT_15\",\n    \"PCIAT-PCIAT_16\", \"PCIAT-PCIAT_17\", \"PCIAT-PCIAT_18\", \"PCIAT-PCIAT_19\",\n    \"PCIAT-PCIAT_20\", \"PCIAT-PCIAT_Total\"\n]\n\n# Drop the specified columns\nprocessed_df = train.drop(columns=columns_to_remove, errors='ignore')\n\n# Save the processed DataFrame to a CSV file\nprocessed_df.to_csv('/kaggle/working/child-mind-institute-problematic-internet-use/processed_demographics_pciat.csv', index=False)\n\nprint(\"Processed DataFrame saved as 'processed_demographics.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.765818Z","iopub.execute_input":"2024-11-18T18:48:46.766136Z","iopub.status.idle":"2024-11-18T18:48:46.825600Z","shell.execute_reply.started":"2024-11-18T18:48:46.766104Z","shell.execute_reply":"2024-11-18T18:48:46.824530Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now I am starting with this processed dataset and will work on remaining fields cleaning and preprocessing","metadata":{}},{"cell_type":"markdown","source":"Internet usage data is crucial to this task because Problematic internet use (PIU), also known as internet addiction or compulsive internet use, refers to excessive and unhealthy use of the internet that interferes with a person’s daily life, responsibilities, and social relationships. The internet usage data provides a direct measure of how much time each participant spends online.","metadata":{}},{"cell_type":"code","source":"# Load the training data\npath=\"/kaggle/working/child-mind-institute-problematic-internet-use/processed_demographics_pciat.csv\"\ntrain = pd.read_csv(path)\ntrain.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.826732Z","iopub.execute_input":"2024-11-18T18:48:46.827047Z","iopub.status.idle":"2024-11-18T18:48:46.860375Z","shell.execute_reply.started":"2024-11-18T18:48:46.827014Z","shell.execute_reply":"2024-11-18T18:48:46.859395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Display the list of columns\ncleaned_columns = train.columns.tolist()\ncleaned_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.861809Z","iopub.execute_input":"2024-11-18T18:48:46.862120Z","iopub.status.idle":"2024-11-18T18:48:46.868504Z","shell.execute_reply.started":"2024-11-18T18:48:46.862090Z","shell.execute_reply":"2024-11-18T18:48:46.867480Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # List of columns to drop\n# columns_to_remove = [\n#     'disobey_time_limits', 'neglect_chores', 'prefer_online_over_family',\n#     'form_online_relationships', 'parent_complains_time', 'grades_suffer',\n#     'check_email_first', 'withdrawn_from_others', 'defensive_secretive',\n#     'sneaking_online', 'alone_in_room_computing', 'strange_calls_online_friends',\n#     'annoyed_if_bothered', 'more_tired_fatigued', 'preoccupied_with_online',\n#     'tantrums_over_interference', 'online_over_hobbies', 'angry_at_time_limits',\n#     'online_over_friends', 'mood_improves_online'\n# ]\n\n# # Remove the specified columns from the cleaned DataFrame\n# further_cleaned_df = train.drop(columns=columns_to_remove, errors='ignore')\n\n# # Save the further cleaned DataFrame to a new CSV\n# output_path_cleaned = '/kaggle/working/child-mind-institute-problematic-internet-use/processed_demographics_pciat1.csv'\n# further_cleaned_df.to_csv(output_path_cleaned, index=False)\n\n# print(f\"Further cleaned DataFrame saved at: {output_path_cleaned}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.869653Z","iopub.execute_input":"2024-11-18T18:48:46.869962Z","iopub.status.idle":"2024-11-18T18:48:46.880926Z","shell.execute_reply.started":"2024-11-18T18:48:46.869932Z","shell.execute_reply":"2024-11-18T18:48:46.879974Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Load the training data\n# path=\"/kaggle/working/child-mind-institute-problematic-internet-use/processed_demographics_pciat.csv\"\n# train = pd.read_csv(path)\n# train.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.882285Z","iopub.execute_input":"2024-11-18T18:48:46.882916Z","iopub.status.idle":"2024-11-18T18:48:46.891402Z","shell.execute_reply.started":"2024-11-18T18:48:46.882867Z","shell.execute_reply":"2024-11-18T18:48:46.890331Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# # Display the list of columns\n# cleaned_columns = train.columns.tolist()\n# cleaned_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.892656Z","iopub.execute_input":"2024-11-18T18:48:46.893011Z","iopub.status.idle":"2024-11-18T18:48:46.901632Z","shell.execute_reply.started":"2024-11-18T18:48:46.892979Z","shell.execute_reply":"2024-11-18T18:48:46.900406Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train['PreInt_EduHx-computerinternet_hoursday'].unique()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.902955Z","iopub.execute_input":"2024-11-18T18:48:46.903383Z","iopub.status.idle":"2024-11-18T18:48:46.913946Z","shell.execute_reply.started":"2024-11-18T18:48:46.903335Z","shell.execute_reply":"2024-11-18T18:48:46.912945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check correlation between numerical features and 'sii'\n# Correlation between Hours of Computer Usage and SII\ncorr_hours_sii = train[['PreInt_EduHx-computerinternet_hoursday', 'sii']].corr()\nprint(\"Correlation between Hours and SII:\\n\", corr_hours_sii)\n\n# Encoding 'PreInt_EduHx-Season' for correlation check\ntrain['Season_Encoded'] = train['PreInt_EduHx-Season'].map({\n    'Spring': 1, 'Summer': 2, 'Fall': 3, 'Winter': 4\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.915101Z","iopub.execute_input":"2024-11-18T18:48:46.915447Z","iopub.status.idle":"2024-11-18T18:48:46.929119Z","shell.execute_reply.started":"2024-11-18T18:48:46.915415Z","shell.execute_reply":"2024-11-18T18:48:46.928118Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from scipy.stats import pointbiserialr\n# Point-biserial correlation between categorical season and hours (numerical)\n# season_hours_corr, _ = pointbiserialr(train['Season_Encoded'].dropna(), train['PreInt_EduHx-computerinternet_hoursday'].dropna())\n# print(f\"Point-biserial correlation between Season and Hours: {season_hours_corr:.2f}\")\n# Remove rows where either 'Season_Encoded' or 'PreInt_EduHx-computerinternet_hoursday' is NaN\ncleaned_data = train.dropna(subset=['Season_Encoded', 'PreInt_EduHx-computerinternet_hoursday'])\n\n# Point-biserial correlation between categorical season and hours (numerical)\nseason_hours_corr, _ = pointbiserialr(cleaned_data['Season_Encoded'], cleaned_data['PreInt_EduHx-computerinternet_hoursday'])\n\nprint(f\"Point-biserial correlation between Season and Hours: {season_hours_corr:.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.930436Z","iopub.execute_input":"2024-11-18T18:48:46.930850Z","iopub.status.idle":"2024-11-18T18:48:46.946162Z","shell.execute_reply.started":"2024-11-18T18:48:46.930803Z","shell.execute_reply":"2024-11-18T18:48:46.945160Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Since the correlation is positive, it suggests that as the \"Season\" variable increases (e.g., from one category to the other, such as Winter to Summer), \"Hours\" tends to increase slightly as well. However, since the correlation is so small, this relationship is statistically insignificant.\nThe correlation of 0.02 suggests that the season (categorical variable) has almost no linear relationship with the number of hours spent on the computer/internet (numerical variable). This is generally a very weak relationship. should not rely heavily on the season to predict or infer anything meaningful about the hours of computer usage in your dataset. The season may not be a strong feature to focus on when modeling the data.","metadata":{}},{"cell_type":"code","source":"# Check the correlation between this season and sii\ncleaned_data = train.dropna(subset=['Season_Encoded'])\n# Point-biserial correlation between Season_Encoded and sii\nseason_sii_corr, _ = pointbiserialr(cleaned_data['Season_Encoded'], cleaned_data['sii'])\nprint(f\"Point-biserial correlation between Season and SII: {season_sii_corr:.2f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.947364Z","iopub.execute_input":"2024-11-18T18:48:46.948039Z","iopub.status.idle":"2024-11-18T18:48:46.966573Z","shell.execute_reply.started":"2024-11-18T18:48:46.947988Z","shell.execute_reply":"2024-11-18T18:48:46.965631Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import scipy.stats as stats\n\n# ANOVA test for Season_Encoded across different levels of sii\nf_stat, p_value = stats.f_oneway(\n    train[train['sii'] == 0]['Season_Encoded'].dropna(),\n    train[train['sii'] == 1]['Season_Encoded'].dropna(),\n    train[train['sii'] == 2]['Season_Encoded'].dropna(),\n    train[train['sii'] == 3]['Season_Encoded'].dropna()\n)\n\nprint(f\"ANOVA F-statistic: {f_stat:.2f}, p-value: {p_value:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.967885Z","iopub.execute_input":"2024-11-18T18:48:46.968232Z","iopub.status.idle":"2024-11-18T18:48:46.983625Z","shell.execute_reply.started":"2024-11-18T18:48:46.968201Z","shell.execute_reply":"2024-11-18T18:48:46.982529Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = train.drop(columns=['PreInt_EduHx-Season','Season_Encoded'], errors='ignore')\ntrain.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:46.984889Z","iopub.execute_input":"2024-11-18T18:48:46.985752Z","iopub.status.idle":"2024-11-18T18:48:47.011251Z","shell.execute_reply.started":"2024-11-18T18:48:46.985704Z","shell.execute_reply":"2024-11-18T18:48:47.010292Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select only numeric columns for correlation\nnumeric_columns = train.select_dtypes(include=['number']).columns\n\nnumeric_columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:47.012535Z","iopub.execute_input":"2024-11-18T18:48:47.012821Z","iopub.status.idle":"2024-11-18T18:48:47.019853Z","shell.execute_reply.started":"2024-11-18T18:48:47.012792Z","shell.execute_reply":"2024-11-18T18:48:47.018832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Calculate the correlation matrix for the numeric features\ncorr_matrix = train[numeric_columns].corr()\ncorr_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:47.021017Z","iopub.execute_input":"2024-11-18T18:48:47.021323Z","iopub.status.idle":"2024-11-18T18:48:47.065401Z","shell.execute_reply.started":"2024-11-18T18:48:47.021293Z","shell.execute_reply":"2024-11-18T18:48:47.064339Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Visualize the correlation matrix using a heatmap\nplt.figure(figsize=(12, 8))  # Adjust the figure size as needed\nsns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n\n# Add a title to the plot\nplt.title('Correlation Matrix of Numeric Features')\n\n# Display the plot\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:47.066573Z","iopub.execute_input":"2024-11-18T18:48:47.066846Z","iopub.status.idle":"2024-11-18T18:48:49.185362Z","shell.execute_reply.started":"2024-11-18T18:48:47.066819Z","shell.execute_reply":"2024-11-18T18:48:49.184423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check correlation between 'PreInt_EduHx-computerinternet_hoursday' and other numerical columns\ncorrelations = corr_matrix['PreInt_EduHx-computerinternet_hoursday'].dropna()\n\n# Drop 'PreInt_EduHx-computerinternet_hoursday' itself from the correlation list\ncorrelations = correlations.drop('PreInt_EduHx-computerinternet_hoursday')\n\n# Show the correlations\nprint(\"Correlation of 'PreInt_EduHx-computerinternet_hoursday' with other features (excluding itself):\")\nprint(correlations)\n\n# Select the most correlated feature (excluding itself)\nmost_correlated_feature = correlations.idxmax()  # The most correlated feature with 'PreInt_EduHx-computerinternet_hoursday'\nprint(f\"Most correlated feature: {most_correlated_feature}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.186591Z","iopub.execute_input":"2024-11-18T18:48:49.186877Z","iopub.status.idle":"2024-11-18T18:48:49.194975Z","shell.execute_reply.started":"2024-11-18T18:48:49.186850Z","shell.execute_reply":"2024-11-18T18:48:49.194044Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Show the first few records with NaN values\nnan_count = train['PreInt_EduHx-computerinternet_hoursday'].isna().sum()\nnan_count","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.196356Z","iopub.execute_input":"2024-11-18T18:48:49.196837Z","iopub.status.idle":"2024-11-18T18:48:49.208180Z","shell.execute_reply.started":"2024-11-18T18:48:49.196791Z","shell.execute_reply":"2024-11-18T18:48:49.207199Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Now, perform imputation using Age (we will use median for each Age group)\nage_medians = train.groupby('Basic_Demos-Age')['PreInt_EduHx-computerinternet_hoursday'].median()\n\n# Function to impute missing values based on Age\ndef impute_based_on_age(row):\n    if pd.isnull(row['PreInt_EduHx-computerinternet_hoursday']):\n        return age_medians.get(row['Basic_Demos-Age'], row['PreInt_EduHx-computerinternet_hoursday'])\n    else:\n        return row['PreInt_EduHx-computerinternet_hoursday']\n\n# Apply the imputation function\ntrain['PreInt_EduHx-computerinternet_hoursday'] = train.apply(impute_based_on_age, axis=1)\n\n# Check if there are any remaining missing values\nremaining_missing = train['PreInt_EduHx-computerinternet_hoursday'].isnull().sum()\nprint(f\"Remaining missing values after imputation: {remaining_missing}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.209336Z","iopub.execute_input":"2024-11-18T18:48:49.209654Z","iopub.status.idle":"2024-11-18T18:48:49.250842Z","shell.execute_reply.started":"2024-11-18T18:48:49.209623Z","shell.execute_reply":"2024-11-18T18:48:49.249787Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.252239Z","iopub.execute_input":"2024-11-18T18:48:49.252588Z","iopub.status.idle":"2024-11-18T18:48:49.278541Z","shell.execute_reply.started":"2024-11-18T18:48:49.252554Z","shell.execute_reply":"2024-11-18T18:48:49.277407Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.preprocessing import LabelEncoder\n\n# # 1. Encode the 'PreInt_EduHx-computerinternet_hoursday' feature into numeric values\n# def encode_internet_usage(df):\n#     label_encoder = LabelEncoder()\n#     df['internet_use_encoded'] = label_encoder.fit_transform(df['PreInt_EduHx-computerinternet_hoursday'])\n#     return df\n\n# # 2. Preprocess the dataset and prepare for visualization and model training\n# def preprocess_and_visualize(df):\n#     # Step 1: Encode the internet usage feature\n#     df_encoded = encode_internet_usage(df)\n    \n#     # Step 2: Create additional features if necessary (e.g., Age Group)\n#     df_encoded['Age Group'] = pd.cut(df_encoded['Basic_Demos-Age'], bins=[5, 12, 15, 18, 22, 65],\n#                                      labels=['Child', 'Early Teen', 'Teen', 'Young Adult', 'Adult'])\n\n#     # Step 3: Visualizations\n#     fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n\n#     # Distribution of internet usage hours (encoded)\n#     ax1 = sns.countplot(x='internet_use_encoded', data=df_encoded, palette=\"Set3\", ax=axes[0])\n#     axes[0].set_title('Distribution of Hours of Internet Use')\n#     axes[0].set_xlabel('Hours per Day Group')\n#     axes[0].set_ylabel('Count')\n\n#     total = len(df_encoded['internet_use_encoded'])\n#     for p in ax1.patches:\n#         count = int(p.get_height())\n#         percentage = '{:.1f}%'.format(100 * count / total)\n#         ax1.annotate(f'{count} ({percentage})', (p.get_x() + p.get_width() / 2., p.get_height()), \n#                      ha='center', va='baseline', fontsize=10, color='black', xytext=(0, 5), \n#                      textcoords='offset points')\n\n#     # Hours of Internet Use by Age\n#     sns.boxplot(y=df_encoded['Basic_Demos-Age'], x=df_encoded['internet_use_encoded'], ax=axes[1], palette=\"Set3\")\n#     axes[1].set_title('Hours of Internet Use by Age')\n#     axes[1].set_ylabel('Age')\n#     axes[1].set_xlabel('Hours per Day Group')\n\n#     # Hours of Internet Use (numeric) by Age Group\n#     sns.boxplot(y='PreInt_EduHx-computerinternet_hoursday', x='Age Group', data=df_encoded, ax=axes[2], palette=\"Set3\")\n#     axes[2].set_title('Internet Hours by Age Group')\n#     axes[2].set_ylabel('Hours per Day (Numeric)')\n#     axes[2].set_xlabel('Age Group')\n\n#     plt.tight_layout()\n#     plt.show()\n\n#     return df_encoded\n\n# # Example usage: Apply the full preprocessing and visualization pipeline\n# train_processed = preprocess_and_visualize(train)\n\n# # Check the processed DataFrame for further analysis\n# print(train_processed.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.279700Z","iopub.execute_input":"2024-11-18T18:48:49.279980Z","iopub.status.idle":"2024-11-18T18:48:49.293393Z","shell.execute_reply.started":"2024-11-18T18:48:49.279951Z","shell.execute_reply":"2024-11-18T18:48:49.292320Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# import pandas as pd\n# import seaborn as sns\n# import matplotlib.pyplot as plt\n# from sklearn.preprocessing import StandardScaler, LabelEncoder\n# from scipy import stats\n\n# # 1. Exploratory Data Analysis (EDA) for 'PreInt_EduHx-computerinternet_hoursday'\n# def eda_computer_internet_usage(df):\n#     # Check the distribution of the 'PreInt_EduHx-computerinternet_hoursday'\n#     print(\"Value counts for 'PreInt_EduHx-computerinternet_hoursday':\")\n#     print(df['PreInt_EduHx-computerinternet_hoursday'].value_counts())\n    \n#     # Visualizing the distribution of the feature\n#     plt.figure(figsize=(8, 6))\n#     sns.countplot(x='PreInt_EduHx-computerinternet_hoursday', data=df)\n#     plt.title('Distribution of Hours of Using Computer/Internet per Day')\n#     plt.xlabel('Hours of Usage per Day')\n#     plt.ylabel('Frequency')\n#     plt.show()\n    \n#     # Check the correlation of this feature with the target variable 'sii'\n#     print(\"\\nCorrelation with 'sii':\")\n#     correlation = df[['PreInt_EduHx-computerinternet_hoursday', 'sii']].corr()\n#     print(correlation)\n\n#     # Checking for missing values\n#     print(\"\\nMissing values in the dataset:\")\n#     print(df['PreInt_EduHx-computerinternet_hoursday'].isnull().sum())\n\n# # 2. Data Cleaning for 'PreInt_EduHx-computerinternet_hoursday'\n# def clean_computer_internet_usage(df):\n#     # Handle missing values by filling with the mode (since it's categorical data)\n#     df['PreInt_EduHx-computerinternet_hoursday'].fillna(df['PreInt_EduHx-computerinternet_hoursday'].mode()[0], inplace=True)\n    \n#     # Ensure the values are within the expected range (0, 1, 2, 3)\n#     valid_values = [0, 1, 2, 3]\n#     df = df[df['PreInt_EduHx-computerinternet_hoursday'].isin(valid_values)]\n    \n#     return df\n\n# # 3. Data Preprocessing for 'PreInt_EduHx-computerinternet_hoursday'\n# def preprocess_computer_internet_usage(df):\n#     # Convert the categorical feature 'PreInt_EduHx-computerinternet_hoursday' into numerical values if needed\n#     # Option 1: Label encoding (0=Less than 1h/day, 1=Around 1h/day, 2=Around 2hs/day, 3=More than 3hs/day)\n#     label_encoder = LabelEncoder()\n#     df['PreInt_EduHx-computerinternet_hoursday_encoded'] = label_encoder.fit_transform(df['PreInt_EduHx-computerinternet_hoursday'])\n    \n#     # Option 2: One-hot encoding, if needed\n#     # df = pd.get_dummies(df, columns=['PreInt_EduHx-computerinternet_hoursday'], drop_first=True)\n    \n#     return df\n\n# # 4. Putting it all together: Full EDA, Cleaning, and Preprocessing\n# def full_process(df):\n#     # Perform EDA\n#     eda_computer_internet_usage(df)\n#     return df\n#     # # Clean the feature (handle missing values and remove outliers)\n#     # df_cleaned = clean_computer_internet_usage(df)\n    \n#     # # Preprocess the feature (encode the categorical feature)\n#     # df_processed = preprocess_computer_internet_usage(df_cleaned)\n    \n#     # # Check the cleaned and processed data\n#     # print(\"\\nProcessed DataFrame:\")\n#     # print(df_processed.head())\n\n#     # return df_processed\n\n# # Example: Apply the full processing pipeline to the data\n# train_processed = full_process(train)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.294832Z","iopub.execute_input":"2024-11-18T18:48:49.295160Z","iopub.status.idle":"2024-11-18T18:48:49.310184Z","shell.execute_reply.started":"2024-11-18T18:48:49.295128Z","shell.execute_reply":"2024-11-18T18:48:49.309195Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.311378Z","iopub.execute_input":"2024-11-18T18:48:49.312288Z","iopub.status.idle":"2024-11-18T18:48:49.346596Z","shell.execute_reply.started":"2024-11-18T18:48:49.312246Z","shell.execute_reply":"2024-11-18T18:48:49.345554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Group by age group and sii, and calculate the mean of internet usage (PreInt_EduHx-computerinternet_hoursday)\ngrouped_data = train.groupby(['age_group', 'sii'])['PreInt_EduHx-computerinternet_hoursday'].mean().reset_index()\n\n# Create a grouped bar plot\nplt.figure(figsize=(10, 6))\nsns.barplot(x='age_group', y='PreInt_EduHx-computerinternet_hoursday', hue='sii', data=grouped_data)\n\n# Set plot labels and title\nplt.title('Internet Usage by Age Group and SII Severity')\nplt.xlabel('Age Group')\nplt.ylabel('Average Internet Usage (hours/day)')\nplt.legend(title='SII Severity')\n\n# Display the plot\nplt.xticks(rotation=45)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.347987Z","iopub.execute_input":"2024-11-18T18:48:49.348394Z","iopub.status.idle":"2024-11-18T18:48:49.737917Z","shell.execute_reply.started":"2024-11-18T18:48:49.348351Z","shell.execute_reply":"2024-11-18T18:48:49.736959Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now we will focus on remaining three fields as part of this notebook EDA","metadata":{}},{"cell_type":"code","source":"# Check for null values in the specified columns\neda_columns = ['SDS-Season', 'SDS-SDS_Total_Raw', 'SDS-SDS_Total_T']\n\n# Count the number of null values in each column\nnull_values = train[eda_columns].isna().sum()\nprint(\"Number of Null values in each column:\")\nprint(null_values)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.739385Z","iopub.execute_input":"2024-11-18T18:48:49.740159Z","iopub.status.idle":"2024-11-18T18:48:49.748487Z","shell.execute_reply.started":"2024-11-18T18:48:49.740106Z","shell.execute_reply":"2024-11-18T18:48:49.747379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eda_columns = ['SDS-SDS_Total_Raw', 'SDS-SDS_Total_T']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.749902Z","iopub.execute_input":"2024-11-18T18:48:49.750581Z","iopub.status.idle":"2024-11-18T18:48:49.759179Z","shell.execute_reply.started":"2024-11-18T18:48:49.750548Z","shell.execute_reply":"2024-11-18T18:48:49.758310Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Descriptive statistics for the specified columns\ndescriptive_stats = train[eda_columns].describe()\nprint(\"\\nDescriptive Statistics for each column:\")\nprint(descriptive_stats)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.760186Z","iopub.execute_input":"2024-11-18T18:48:49.760494Z","iopub.status.idle":"2024-11-18T18:48:49.779512Z","shell.execute_reply.started":"2024-11-18T18:48:49.760439Z","shell.execute_reply":"2024-11-18T18:48:49.778253Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Select only numeric columns for correlation\nnumeric_columns = train.select_dtypes(include=['number']).columns\n\n# Calculate correlation for the three SDS columns with other numeric columns\ncorrelation_matrix = train[eda_columns + list(numeric_columns)].corr()\n\n# Filter the correlation matrix for the three SDS columns\nsds_correlation = correlation_matrix[eda_columns]\nprint(\"\\nCorrelation of SDS columns with other features:\")\nprint(sds_correlation)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.780833Z","iopub.execute_input":"2024-11-18T18:48:49.781519Z","iopub.status.idle":"2024-11-18T18:48:49.801336Z","shell.execute_reply.started":"2024-11-18T18:48:49.781453Z","shell.execute_reply":"2024-11-18T18:48:49.800191Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation with the target variable (SII)\ntarget_variable = 'sii'  # Replace with the actual target variable name\nsii_correlation = train[eda_columns + [target_variable]].corr()[target_variable]\nprint(\"\\nCorrelation of SDS columns with SII:\")\nprint(sii_correlation)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.802713Z","iopub.execute_input":"2024-11-18T18:48:49.803127Z","iopub.status.idle":"2024-11-18T18:48:49.811671Z","shell.execute_reply.started":"2024-11-18T18:48:49.803080Z","shell.execute_reply":"2024-11-18T18:48:49.810547Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"SDS-SDS_Total_T has a slightly higher correlation than SDS-SDS_Total_Raw, which might indicate that the T-Score could be a better predictor of sii.","metadata":{}},{"cell_type":"code","source":"# Plotting bar plots for mean SDS-SDS_Total_Raw and SDS-SDS_Total_T by SDS-Season\nfig, axes = plt.subplots(1, 2, figsize=(15, 6))\n\n# Bar plot for mean SDS-SDS_Total_Raw by SDS-Season\nsns.barplot(data=train, x='SDS-Season', y='SDS-SDS_Total_Raw', ax=axes[0], estimator='mean', ci=None)\naxes[0].set_title('Mean SDS-SDS_Total_Raw by SDS-Season')\naxes[0].set_xlabel('Season')\naxes[0].set_ylabel('Mean SDS-SDS_Total_Raw')\n\n# Bar plot for mean SDS-SDS_Total_T by SDS-Season\nsns.barplot(data=train, x='SDS-Season', y='SDS-SDS_Total_T', ax=axes[1], estimator='mean', ci=None)\naxes[1].set_title('Mean SDS-SDS_Total_T by SDS-Season')\naxes[1].set_xlabel('Season')\naxes[1].set_ylabel('Mean SDS-SDS_Total_T')\n\n# Show the plots\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:49.812928Z","iopub.execute_input":"2024-11-18T18:48:49.813249Z","iopub.status.idle":"2024-11-18T18:48:50.268819Z","shell.execute_reply.started":"2024-11-18T18:48:49.813218Z","shell.execute_reply":"2024-11-18T18:48:50.267777Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"it is same for all the seasons","metadata":{}},{"cell_type":"code","source":"# Drop the 'SDS-Season' column from the dataset\ntrain = train.drop(columns=['SDS-Season'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.269921Z","iopub.execute_input":"2024-11-18T18:48:50.270197Z","iopub.status.idle":"2024-11-18T18:48:50.275849Z","shell.execute_reply.started":"2024-11-18T18:48:50.270169Z","shell.execute_reply":"2024-11-18T18:48:50.274802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.277226Z","iopub.execute_input":"2024-11-18T18:48:50.277553Z","iopub.status.idle":"2024-11-18T18:48:50.309531Z","shell.execute_reply.started":"2024-11-18T18:48:50.277521Z","shell.execute_reply":"2024-11-18T18:48:50.308433Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.310902Z","iopub.execute_input":"2024-11-18T18:48:50.311214Z","iopub.status.idle":"2024-11-18T18:48:50.318708Z","shell.execute_reply.started":"2024-11-18T18:48:50.311180Z","shell.execute_reply":"2024-11-18T18:48:50.317720Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for rows where 'SDS-SDS_Total_T' is null but 'SDS-SDS_Total_Raw' is not\nmask = train['SDS-SDS_Total_T'].isna() & train['SDS-SDS_Total_Raw'].notna()\n\n# Count the number of such rows\nnum_null_in_T_not_in_Raw = mask.sum()\n\nprint(f\"Number of rows where 'SDS-SDS_Total_T' is null but 'SDS-SDS_Total_Raw' is not: {num_null_in_T_not_in_Raw}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.320215Z","iopub.execute_input":"2024-11-18T18:48:50.320652Z","iopub.status.idle":"2024-11-18T18:48:50.330378Z","shell.execute_reply.started":"2024-11-18T18:48:50.320607Z","shell.execute_reply":"2024-11-18T18:48:50.329484Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Impute missing values in 'SDS-SDS_Total_T' based on the corresponding 'SDS-SDS_Total_Raw'\ntrain['SDS-SDS_Total_T'] = train['SDS-SDS_Total_T'].fillna(train['SDS-SDS_Total_Raw'])\n\n# Verify if the missing value is imputed\nprint(train['SDS-SDS_Total_T'].isna().sum())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.331716Z","iopub.execute_input":"2024-11-18T18:48:50.332041Z","iopub.status.idle":"2024-11-18T18:48:50.346854Z","shell.execute_reply.started":"2024-11-18T18:48:50.332009Z","shell.execute_reply":"2024-11-18T18:48:50.345810Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop the 'SDS-Season' column from the dataset\ntrain = train.drop(columns=['SDS-SDS_Total_Raw'])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.348300Z","iopub.execute_input":"2024-11-18T18:48:50.348727Z","iopub.status.idle":"2024-11-18T18:48:50.359887Z","shell.execute_reply.started":"2024-11-18T18:48:50.348681Z","shell.execute_reply":"2024-11-18T18:48:50.359034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Step 1: Select only numeric columns\nnumeric_columns = train.select_dtypes(include=['number']).columns\n\n# Step 2: Calculate correlation of each numeric feature with 'SDS-SDS_Total_T'\ncorrelations = train[numeric_columns].corrwith(train['SDS-SDS_Total_T'])\n\ncorrelations\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.361083Z","iopub.execute_input":"2024-11-18T18:48:50.361403Z","iopub.status.idle":"2024-11-18T18:48:50.385260Z","shell.execute_reply.started":"2024-11-18T18:48:50.361372Z","shell.execute_reply":"2024-11-18T18:48:50.384272Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 3: Set a correlation threshold (e.g., 0.4) for feature selection\nthreshold = 0.2\nselected_features = correlations[correlations.abs() > threshold].index\n\n# Step 4: Display the selected features based on correlation with 'SDS-SDS_Total_T'\nprint(\"Selected Features based on correlation with 'SDS-SDS_Total_T':\")\nprint(selected_features)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.386309Z","iopub.execute_input":"2024-11-18T18:48:50.386623Z","iopub.status.idle":"2024-11-18T18:48:50.392833Z","shell.execute_reply.started":"2024-11-18T18:48:50.386591Z","shell.execute_reply":"2024-11-18T18:48:50.391911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 5: Create a correlation matrix for the selected features\nselected_features_matrix = train[selected_features].corr()\n\n# Step 6: Visualize the correlation matrix of the selected features\nplt.figure(figsize=(8, 6))\nsns.heatmap(selected_features_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\nplt.title('Correlation Matrix of Selected Features')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.394106Z","iopub.execute_input":"2024-11-18T18:48:50.394483Z","iopub.status.idle":"2024-11-18T18:48:50.916543Z","shell.execute_reply.started":"2024-11-18T18:48:50.394426Z","shell.execute_reply":"2024-11-18T18:48:50.915548Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.impute import KNNImputer\n# Step 5: Apply KNN imputation to fill the missing values in 'SDS-SDS_Total_T'\nknn_imputer = KNNImputer(n_neighbors=5)\n\n# Impute missing values in the selected features (including 'SDS-SDS_Total_T')\n# train_imputed = train.copy()\ntrain[selected_features] = knn_imputer.fit_transform(train[selected_features])\n\n# Step 6: Check how many missing values remain in 'SDS-SDS_Total_T' after imputation\nprint(f\"Missing values in 'SDS-SDS_Total_T' after KNN imputation: {train['SDS-SDS_Total_T'].isnull().sum()}\")\n\n# Visualize the distribution of 'SDS-SDS_Total_T' before and after imputation\nplt.figure(figsize=(12, 6))\n\n# Before imputation\nplt.subplot(1, 2, 1)\nsns.histplot(train['SDS-SDS_Total_T'], kde=True, color='blue', bins=30)\nplt.title('Distribution of SDS-SDS_Total_T Before Imputation')\nplt.xlabel('SDS-SDS_Total_T')\nplt.ylabel('Frequency')\n\n# After imputation\nplt.subplot(1, 2, 2)\nsns.histplot(train['SDS-SDS_Total_T'], kde=True, color='green', bins=30)\nplt.title('Distribution of SDS-SDS_Total_T After KNN Imputation')\nplt.xlabel('SDS-SDS_Total_T')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n# Optional: Display a preview of the imputed data\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:50.918018Z","iopub.execute_input":"2024-11-18T18:48:50.918753Z","iopub.status.idle":"2024-11-18T18:48:51.643995Z","shell.execute_reply.started":"2024-11-18T18:48:50.918705Z","shell.execute_reply":"2024-11-18T18:48:51.643091Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Drop NaN values for simplicity\ndf = train[['SDS-SDS_Total_T', 'sii']]\n\n\nplt.figure(figsize=(12, 6))\nsns.boxplot(data=df, x='sii', y='SDS-SDS_Total_T', palette='Set3')\nplt.title('SDS-SDS_Total_T by SII')\nplt.xlabel('SII')\nplt.ylabel('SDS-SDS_Total_T')\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:51.645359Z","iopub.execute_input":"2024-11-18T18:48:51.645785Z","iopub.status.idle":"2024-11-18T18:48:51.948080Z","shell.execute_reply.started":"2024-11-18T18:48:51.645738Z","shell.execute_reply":"2024-11-18T18:48:51.947139Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Step 1: Check for missing values (NaN) in the final dataset after imputation\nmissing_values = train.isna().sum()\n\n# Step 2: Display columns that have missing values\nprint(\"Missing values in each column of the final dataset after imputation:\")\nprint(missing_values[missing_values == 0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:51.949234Z","iopub.execute_input":"2024-11-18T18:48:51.949549Z","iopub.status.idle":"2024-11-18T18:48:51.958428Z","shell.execute_reply.started":"2024-11-18T18:48:51.949518Z","shell.execute_reply":"2024-11-18T18:48:51.957379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:51.959681Z","iopub.execute_input":"2024-11-18T18:48:51.959979Z","iopub.status.idle":"2024-11-18T18:48:51.971536Z","shell.execute_reply.started":"2024-11-18T18:48:51.959946Z","shell.execute_reply":"2024-11-18T18:48:51.970395Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# List of columns to drop\ncolumns_to_drop = [\n    'disobey_time_limits', 'neglect_chores', 'prefer_online_over_family',\n    'form_online_relationships', 'parent_complains_time', 'grades_suffer',\n    'check_email_first', 'withdrawn_from_others', 'defensive_secretive',\n    'sneaking_online', 'alone_in_room_computing', 'strange_calls_online_friends',\n    'annoyed_if_bothered', 'more_tired_fatigued', 'preoccupied_with_online',\n    'tantrums_over_interference', 'online_over_hobbies', 'angry_at_time_limits',\n    'online_over_friends', 'mood_improves_online','PCIAT_total'\n]\n\n# Drop the specified columns from the DataFrame\ntrain.drop(columns=columns_to_drop, inplace=True)\n\ntrain.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:51.972811Z","iopub.execute_input":"2024-11-18T18:48:51.973193Z","iopub.status.idle":"2024-11-18T18:48:51.993718Z","shell.execute_reply.started":"2024-11-18T18:48:51.973149Z","shell.execute_reply":"2024-11-18T18:48:51.992306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the processed DataFrame to a CSV file\ntrain.to_csv('/kaggle/working/child-mind-institute-problematic-internet-use/cleaned.csv', index=False)\n\nprint(\"Processed DataFrame saved as 'cleaned.csv'.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-18T18:48:51.994822Z","iopub.execute_input":"2024-11-18T18:48:51.995221Z","iopub.status.idle":"2024-11-18T18:48:52.012485Z","shell.execute_reply.started":"2024-11-18T18:48:51.995173Z","shell.execute_reply":"2024-11-18T18:48:52.011526Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test.head(21)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:41:26.752034Z","iopub.execute_input":"2024-11-22T09:41:26.752452Z","iopub.status.idle":"2024-11-22T09:41:26.788935Z","shell.execute_reply.started":"2024-11-22T09:41:26.752419Z","shell.execute_reply":"2024-11-22T09:41:26.787463Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"          id Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex  \\\n0   00008ff9                      Fall                5                0   \n1   000fd460                    Summer                9                0   \n2   00105258                    Summer               10                1   \n3   00115b9f                    Winter                9                0   \n4   0016bb22                    Spring               18                1   \n5   001f3379                    Spring               13                1   \n6   0038ba98                      Fall               10                0   \n7   0068a485                      Fall               10                1   \n8   0069fbed                    Summer               15                0   \n9   0083e397                    Summer               19                1   \n10  0087dd65                    Spring               11                1   \n11  00abe655                      Fall               11                0   \n12  00ae59c9                      Fall               13                0   \n13  00af6387                    Spring               12                0   \n14  00bd4359                    Spring               12                0   \n15  00c0cd71                    Winter                7                0   \n16  00d56d4b                    Spring                5                1   \n17  00d9913d                      Fall               10                1   \n18  00e6167c                    Winter                6                0   \n19  00ebc35d                    Winter               10                0   \n\n   CGAS-Season  CGAS-CGAS_Score Physical-Season  Physical-BMI  \\\n0       Winter             51.0            Fall     16.877316   \n1          NaN              NaN            Fall     14.035590   \n2         Fall             71.0            Fall     16.648696   \n3         Fall             71.0          Summer     18.292347   \n4       Summer              NaN             NaN           NaN   \n5       Winter             50.0          Summer     22.279952   \n6          NaN              NaN            Fall     19.660760   \n7          NaN              NaN            Fall     16.861286   \n8          NaN              NaN          Spring           NaN   \n9       Summer              NaN             NaN           NaN   \n10         NaN              NaN             NaN           NaN   \n11      Summer             66.0             NaN           NaN   \n12         NaN              NaN          Winter     21.079065   \n13         NaN              NaN          Spring     15.544111   \n14         NaN              NaN             NaN           NaN   \n15      Summer             51.0          Spring     29.315775   \n16      Summer             80.0          Spring     17.284504   \n17         NaN              NaN            Fall     19.893157   \n18      Spring             60.0          Winter     30.094649   \n19         NaN              NaN             NaN           NaN   \n\n    Physical-Height  Physical-Weight  ...  BIA-BIA_TBW  PAQ_A-Season  \\\n0             46.00             50.8  ...      32.6909           NaN   \n1             48.00             46.0  ...      27.0552           NaN   \n2             56.50             75.6  ...          NaN           NaN   \n3             56.00             81.6  ...      45.9966           NaN   \n4               NaN              NaN  ...          NaN        Summer   \n5             59.50            112.2  ...      63.1265           NaN   \n6             55.00             84.6  ...      47.2211           NaN   \n7             59.25             84.2  ...      50.4767           NaN   \n8               NaN              NaN  ...          NaN           NaN   \n9               NaN              NaN  ...          NaN           NaN   \n10              NaN              NaN  ...          NaN           NaN   \n11              NaN              NaN  ...          NaN           NaN   \n12            57.75            100.0  ...      56.0118           NaN   \n13            60.00             79.6  ...          NaN           NaN   \n14              NaN              NaN  ...          NaN           NaN   \n15            54.00            121.6  ...          NaN           NaN   \n16            44.00             47.6  ...          NaN           NaN   \n17            55.00             85.6  ...          NaN           NaN   \n18            37.50             60.2  ...      38.7638           NaN   \n19              NaN              NaN  ...          NaN           NaN   \n\n    PAQ_A-PAQ_A_Total  PAQ_C-Season PAQ_C-PAQ_C_Total  SDS-Season  \\\n0                 NaN           NaN               NaN         NaN   \n1                 NaN          Fall             2.340        Fall   \n2                 NaN        Summer             2.170        Fall   \n3                 NaN        Winter             2.451      Summer   \n4                1.04           NaN               NaN         NaN   \n5                 NaN        Spring             4.110      Summer   \n6                 NaN        Winter             3.670      Winter   \n7                 NaN          Fall             1.270         NaN   \n8                 NaN           NaN               NaN         NaN   \n9                 NaN           NaN               NaN         NaN   \n10                NaN           NaN               NaN         NaN   \n11                NaN        Winter             1.100      Winter   \n12                NaN          Fall             3.020        Fall   \n13                NaN        Spring             1.220         NaN   \n14                NaN           NaN               NaN         NaN   \n15                NaN           NaN               NaN      Spring   \n16                NaN           NaN               NaN      Spring   \n17                NaN           NaN               NaN         NaN   \n18                NaN           NaN               NaN      Winter   \n19                NaN           NaN               NaN         NaN   \n\n    SDS-SDS_Total_Raw  SDS-SDS_Total_T PreInt_EduHx-Season  \\\n0                 NaN              NaN                Fall   \n1                46.0             64.0              Summer   \n2                38.0             54.0              Summer   \n3                31.0             45.0              Winter   \n4                 NaN              NaN                 NaN   \n5                40.0             56.0              Spring   \n6                27.0             40.0                Fall   \n7                 NaN              NaN                Fall   \n8                 NaN              NaN              Summer   \n9                 NaN              NaN                 NaN   \n10                NaN              NaN              Spring   \n11               42.0             59.0                Fall   \n12               33.0             47.0                Fall   \n13                NaN              NaN              Spring   \n14                NaN              NaN              Spring   \n15               35.0             50.0              Winter   \n16               37.0             53.0              Spring   \n17                NaN              NaN                Fall   \n18               39.0             55.0              Winter   \n19                NaN              NaN              Winter   \n\n    PreInt_EduHx-computerinternet_hoursday  \n0                                      3.0  \n1                                      0.0  \n2                                      2.0  \n3                                      0.0  \n4                                      NaN  \n5                                      0.0  \n6                                      3.0  \n7                                      2.0  \n8                                      2.0  \n9                                      NaN  \n10                                     NaN  \n11                                     0.0  \n12                                     1.0  \n13                                     NaN  \n14                                     2.0  \n15                                     2.0  \n16                                     0.0  \n17                                     1.0  \n18                                     3.0  \n19                                     2.0  \n\n[20 rows x 59 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Enroll_Season</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>CGAS-Season</th>\n      <th>CGAS-CGAS_Score</th>\n      <th>Physical-Season</th>\n      <th>Physical-BMI</th>\n      <th>Physical-Height</th>\n      <th>Physical-Weight</th>\n      <th>...</th>\n      <th>BIA-BIA_TBW</th>\n      <th>PAQ_A-Season</th>\n      <th>PAQ_A-PAQ_A_Total</th>\n      <th>PAQ_C-Season</th>\n      <th>PAQ_C-PAQ_C_Total</th>\n      <th>SDS-Season</th>\n      <th>SDS-SDS_Total_Raw</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-Season</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>Fall</td>\n      <td>5</td>\n      <td>0</td>\n      <td>Winter</td>\n      <td>51.0</td>\n      <td>Fall</td>\n      <td>16.877316</td>\n      <td>46.00</td>\n      <td>50.8</td>\n      <td>...</td>\n      <td>32.6909</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>Summer</td>\n      <td>9</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>14.035590</td>\n      <td>48.00</td>\n      <td>46.0</td>\n      <td>...</td>\n      <td>27.0552</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>2.340</td>\n      <td>Fall</td>\n      <td>46.0</td>\n      <td>64.0</td>\n      <td>Summer</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>Summer</td>\n      <td>10</td>\n      <td>1</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Fall</td>\n      <td>16.648696</td>\n      <td>56.50</td>\n      <td>75.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>2.170</td>\n      <td>Fall</td>\n      <td>38.0</td>\n      <td>54.0</td>\n      <td>Summer</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>Winter</td>\n      <td>9</td>\n      <td>0</td>\n      <td>Fall</td>\n      <td>71.0</td>\n      <td>Summer</td>\n      <td>18.292347</td>\n      <td>56.00</td>\n      <td>81.6</td>\n      <td>...</td>\n      <td>45.9966</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>2.451</td>\n      <td>Summer</td>\n      <td>31.0</td>\n      <td>45.0</td>\n      <td>Winter</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>Spring</td>\n      <td>18</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>1.04</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>001f3379</td>\n      <td>Spring</td>\n      <td>13</td>\n      <td>1</td>\n      <td>Winter</td>\n      <td>50.0</td>\n      <td>Summer</td>\n      <td>22.279952</td>\n      <td>59.50</td>\n      <td>112.2</td>\n      <td>...</td>\n      <td>63.1265</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>4.110</td>\n      <td>Summer</td>\n      <td>40.0</td>\n      <td>56.0</td>\n      <td>Spring</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0038ba98</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>19.660760</td>\n      <td>55.00</td>\n      <td>84.6</td>\n      <td>...</td>\n      <td>47.2211</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>3.670</td>\n      <td>Winter</td>\n      <td>27.0</td>\n      <td>40.0</td>\n      <td>Fall</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0068a485</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>16.861286</td>\n      <td>59.25</td>\n      <td>84.2</td>\n      <td>...</td>\n      <td>50.4767</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>1.270</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0069fbed</td>\n      <td>Summer</td>\n      <td>15</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Summer</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>Summer</td>\n      <td>19</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>Spring</td>\n      <td>11</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00abe655</td>\n      <td>Fall</td>\n      <td>11</td>\n      <td>0</td>\n      <td>Summer</td>\n      <td>66.0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>1.100</td>\n      <td>Winter</td>\n      <td>42.0</td>\n      <td>59.0</td>\n      <td>Fall</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00ae59c9</td>\n      <td>Fall</td>\n      <td>13</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>21.079065</td>\n      <td>57.75</td>\n      <td>100.0</td>\n      <td>...</td>\n      <td>56.0118</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>3.020</td>\n      <td>Fall</td>\n      <td>33.0</td>\n      <td>47.0</td>\n      <td>Fall</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>Spring</td>\n      <td>12</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>15.544111</td>\n      <td>60.00</td>\n      <td>79.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>1.220</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00bd4359</td>\n      <td>Spring</td>\n      <td>12</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00c0cd71</td>\n      <td>Winter</td>\n      <td>7</td>\n      <td>0</td>\n      <td>Summer</td>\n      <td>51.0</td>\n      <td>Spring</td>\n      <td>29.315775</td>\n      <td>54.00</td>\n      <td>121.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>35.0</td>\n      <td>50.0</td>\n      <td>Winter</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>00d56d4b</td>\n      <td>Spring</td>\n      <td>5</td>\n      <td>1</td>\n      <td>Summer</td>\n      <td>80.0</td>\n      <td>Spring</td>\n      <td>17.284504</td>\n      <td>44.00</td>\n      <td>47.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Spring</td>\n      <td>37.0</td>\n      <td>53.0</td>\n      <td>Spring</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>00d9913d</td>\n      <td>Fall</td>\n      <td>10</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>19.893157</td>\n      <td>55.00</td>\n      <td>85.6</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Fall</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>00e6167c</td>\n      <td>Winter</td>\n      <td>6</td>\n      <td>0</td>\n      <td>Spring</td>\n      <td>60.0</td>\n      <td>Winter</td>\n      <td>30.094649</td>\n      <td>37.50</td>\n      <td>60.2</td>\n      <td>...</td>\n      <td>38.7638</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>39.0</td>\n      <td>55.0</td>\n      <td>Winter</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00ebc35d</td>\n      <td>Winter</td>\n      <td>10</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Winter</td>\n      <td>2.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>20 rows × 59 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'df' is your DataFrame and you want to keep 'column1', 'column2', and 'column3'\ncolumns_to_retain = ['id', 'Basic_Demos-Age', 'Basic_Demos-Sex','SDS-SDS_Total_T','PreInt_EduHx-computerinternet_hoursday']\ntest_filtered = test[columns_to_retain]\n\n# Display the filtered DataFrame\nprint(test_filtered)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:46:43.714499Z","iopub.execute_input":"2024-11-22T09:46:43.714932Z","iopub.status.idle":"2024-11-22T09:46:43.727283Z","shell.execute_reply.started":"2024-11-22T09:46:43.714900Z","shell.execute_reply":"2024-11-22T09:46:43.726094Z"}},"outputs":[{"name":"stdout","text":"          id  Basic_Demos-Age  Basic_Demos-Sex  SDS-SDS_Total_T  \\\n0   00008ff9                5                0              NaN   \n1   000fd460                9                0             64.0   \n2   00105258               10                1             54.0   \n3   00115b9f                9                0             45.0   \n4   0016bb22               18                1              NaN   \n5   001f3379               13                1             56.0   \n6   0038ba98               10                0             40.0   \n7   0068a485               10                1              NaN   \n8   0069fbed               15                0              NaN   \n9   0083e397               19                1              NaN   \n10  0087dd65               11                1              NaN   \n11  00abe655               11                0             59.0   \n12  00ae59c9               13                0             47.0   \n13  00af6387               12                0              NaN   \n14  00bd4359               12                0              NaN   \n15  00c0cd71                7                0             50.0   \n16  00d56d4b                5                1             53.0   \n17  00d9913d               10                1              NaN   \n18  00e6167c                6                0             55.0   \n19  00ebc35d               10                0              NaN   \n\n    PreInt_EduHx-computerinternet_hoursday  \n0                                      3.0  \n1                                      0.0  \n2                                      2.0  \n3                                      0.0  \n4                                      NaN  \n5                                      0.0  \n6                                      3.0  \n7                                      2.0  \n8                                      2.0  \n9                                      NaN  \n10                                     NaN  \n11                                     0.0  \n12                                     1.0  \n13                                     NaN  \n14                                     2.0  \n15                                     2.0  \n16                                     0.0  \n17                                     1.0  \n18                                     3.0  \n19                                     2.0  \n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming 'test_filtered' is already defined\nna_counts = test_filtered.isnull().sum()\n\n# Display the count of missing values for each column\nprint(na_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:49:21.652208Z","iopub.execute_input":"2024-11-22T09:49:21.652594Z","iopub.status.idle":"2024-11-22T09:49:21.663174Z","shell.execute_reply.started":"2024-11-22T09:49:21.652562Z","shell.execute_reply":"2024-11-22T09:49:21.661796Z"}},"outputs":[{"name":"stdout","text":"id                                         0\nBasic_Demos-Age                            0\nBasic_Demos-Sex                            0\nSDS-SDS_Total_T                           10\nPreInt_EduHx-computerinternet_hoursday     4\ndtype: int64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Drop the 'id' column from the DataFrame\ntest_filtered_without_id = test_filtered.drop(columns=['id'])\n\n# Calculate the correlation matrix without the 'id' column\ncorrelation_matrix = test_filtered_without_id.corr()\n\n# Display the correlation matrix\nprint(correlation_matrix)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:51:06.642186Z","iopub.execute_input":"2024-11-22T09:51:06.642580Z","iopub.status.idle":"2024-11-22T09:51:06.654797Z","shell.execute_reply.started":"2024-11-22T09:51:06.642546Z","shell.execute_reply":"2024-11-22T09:51:06.653468Z"}},"outputs":[{"name":"stdout","text":"                                        Basic_Demos-Age  Basic_Demos-Sex  \\\nBasic_Demos-Age                                1.000000         0.281050   \nBasic_Demos-Sex                                0.281050         1.000000   \nSDS-SDS_Total_T                               -0.057782         0.199747   \nPreInt_EduHx-computerinternet_hoursday        -0.177640        -0.264236   \n\n                                        SDS-SDS_Total_T  \\\nBasic_Demos-Age                               -0.057782   \nBasic_Demos-Sex                                0.199747   \nSDS-SDS_Total_T                                1.000000   \nPreInt_EduHx-computerinternet_hoursday        -0.433951   \n\n                                        PreInt_EduHx-computerinternet_hoursday  \nBasic_Demos-Age                                                      -0.177640  \nBasic_Demos-Sex                                                      -0.264236  \nSDS-SDS_Total_T                                                      -0.433951  \nPreInt_EduHx-computerinternet_hoursday                                1.000000  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Check if both columns have missing values in the same row in the original test_filtered DataFrame\nboth_missing = test_filtered['SDS-SDS_Total_T'].isna() & test_filtered['PreInt_EduHx-computerinternet_hoursday'].isna()\n\n# Display the rows where both columns have missing values\nrows_with_both_missing = test_filtered[both_missing]\n\n# Display the rows where both columns have NaN values\nrows_with_both_missing\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:53:07.695226Z","iopub.execute_input":"2024-11-22T09:53:07.696265Z","iopub.status.idle":"2024-11-22T09:53:07.710838Z","shell.execute_reply.started":"2024-11-22T09:53:07.696220Z","shell.execute_reply":"2024-11-22T09:53:07.709685Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"          id  Basic_Demos-Age  Basic_Demos-Sex  SDS-SDS_Total_T  \\\n4   0016bb22               18                1              NaN   \n9   0083e397               19                1              NaN   \n10  0087dd65               11                1              NaN   \n13  00af6387               12                0              NaN   \n\n    PreInt_EduHx-computerinternet_hoursday  \n4                                      NaN  \n9                                      NaN  \n10                                     NaN  \n13                                     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>18</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>19</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>11</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>12</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.impute import KNNImputer\n\n# Assuming test_filtered is your DataFrame\n\n# Step 1: Handle the rows where both columns have NaN values (mean or median imputation)\ntest_filtered.loc[test_filtered['SDS-SDS_Total_T'].isna() & test_filtered['PreInt_EduHx-computerinternet_hoursday'].isna(), 'SDS-SDS_Total_T'] = test_filtered['SDS-SDS_Total_T'].median()\ntest_filtered.loc[test_filtered['SDS-SDS_Total_T'].isna() & test_filtered['PreInt_EduHx-computerinternet_hoursday'].isna(), 'PreInt_EduHx-computerinternet_hoursday'] = test_filtered['PreInt_EduHx-computerinternet_hoursday'].median()\n\n# Step 2: For the other rows with single NaN values, use KNN imputation\n# Initialize KNN imputer with k=3\nknn_imputer = KNNImputer(n_neighbors=3)\n\n# Apply KNN imputation to only the rows that have NaN values in either column\ntest_filtered[['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']] = knn_imputer.fit_transform(test_filtered[['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']].values)\n\n# Print the final imputed DataFrame\ntest_filtered\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:56:14.118356Z","iopub.execute_input":"2024-11-22T09:56:14.118820Z","iopub.status.idle":"2024-11-22T09:56:14.142948Z","shell.execute_reply.started":"2024-11-22T09:56:14.118781Z","shell.execute_reply":"2024-11-22T09:56:14.141428Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_30/2972849012.py:15: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  test_filtered[['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']] = knn_imputer.fit_transform(test_filtered[['SDS-SDS_Total_T', 'PreInt_EduHx-computerinternet_hoursday']].values)\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"          id  Basic_Demos-Age  Basic_Demos-Sex  SDS-SDS_Total_T  \\\n0   00008ff9                5                0        48.333333   \n1   000fd460                9                0        64.000000   \n2   00105258               10                1        54.000000   \n3   00115b9f                9                0        45.000000   \n4   0016bb22               18                1        53.500000   \n5   001f3379               13                1        56.000000   \n6   0038ba98               10                0        40.000000   \n7   0068a485               10                1        48.000000   \n8   0069fbed               15                0        48.000000   \n9   0083e397               19                1        53.500000   \n10  0087dd65               11                1        53.500000   \n11  00abe655               11                0        59.000000   \n12  00ae59c9               13                0        47.000000   \n13  00af6387               12                0        53.500000   \n14  00bd4359               12                0        48.000000   \n15  00c0cd71                7                0        50.000000   \n16  00d56d4b                5                1        53.000000   \n17  00d9913d               10                1        48.666667   \n18  00e6167c                6                0        55.000000   \n19  00ebc35d               10                0        48.000000   \n\n    PreInt_EduHx-computerinternet_hoursday  \n0                                 3.000000  \n1                                 0.000000  \n2                                 2.000000  \n3                                 0.000000  \n4                                 1.666667  \n5                                 0.000000  \n6                                 3.000000  \n7                                 2.000000  \n8                                 2.000000  \n9                                 1.666667  \n10                                1.666667  \n11                                0.000000  \n12                                1.000000  \n13                                1.666667  \n14                                2.000000  \n15                                2.000000  \n16                                0.000000  \n17                                1.000000  \n18                                3.000000  \n19                                2.000000  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Basic_Demos-Age</th>\n      <th>Basic_Demos-Sex</th>\n      <th>SDS-SDS_Total_T</th>\n      <th>PreInt_EduHx-computerinternet_hoursday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008ff9</td>\n      <td>5</td>\n      <td>0</td>\n      <td>48.333333</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000fd460</td>\n      <td>9</td>\n      <td>0</td>\n      <td>64.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00105258</td>\n      <td>10</td>\n      <td>1</td>\n      <td>54.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00115b9f</td>\n      <td>9</td>\n      <td>0</td>\n      <td>45.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0016bb22</td>\n      <td>18</td>\n      <td>1</td>\n      <td>53.500000</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>001f3379</td>\n      <td>13</td>\n      <td>1</td>\n      <td>56.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0038ba98</td>\n      <td>10</td>\n      <td>0</td>\n      <td>40.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0068a485</td>\n      <td>10</td>\n      <td>1</td>\n      <td>48.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0069fbed</td>\n      <td>15</td>\n      <td>0</td>\n      <td>48.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0083e397</td>\n      <td>19</td>\n      <td>1</td>\n      <td>53.500000</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0087dd65</td>\n      <td>11</td>\n      <td>1</td>\n      <td>53.500000</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>00abe655</td>\n      <td>11</td>\n      <td>0</td>\n      <td>59.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>00ae59c9</td>\n      <td>13</td>\n      <td>0</td>\n      <td>47.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>00af6387</td>\n      <td>12</td>\n      <td>0</td>\n      <td>53.500000</td>\n      <td>1.666667</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>00bd4359</td>\n      <td>12</td>\n      <td>0</td>\n      <td>48.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>00c0cd71</td>\n      <td>7</td>\n      <td>0</td>\n      <td>50.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>00d56d4b</td>\n      <td>5</td>\n      <td>1</td>\n      <td>53.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>00d9913d</td>\n      <td>10</td>\n      <td>1</td>\n      <td>48.666667</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>00e6167c</td>\n      <td>6</td>\n      <td>0</td>\n      <td>55.000000</td>\n      <td>3.000000</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>00ebc35d</td>\n      <td>10</td>\n      <td>0</td>\n      <td>48.000000</td>\n      <td>2.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# Save the DataFrame to a CSV file in the Kaggle directory\ntest_filtered.to_csv('/kaggle/working/filtered_test_data.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T09:56:56.321217Z","iopub.execute_input":"2024-11-22T09:56:56.321689Z","iopub.status.idle":"2024-11-22T09:56:56.331633Z","shell.execute_reply.started":"2024-11-22T09:56:56.321652Z","shell.execute_reply":"2024-11-22T09:56:56.330240Z"}},"outputs":[],"execution_count":13}]}